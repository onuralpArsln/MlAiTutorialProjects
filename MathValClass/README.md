# Numerical Value Classification

This folder consists of projects that trains models to classify data using numerical values.

Since data is already in numerical from machine learning methods that based on statistical models are used.

Here is the list of methods that will be investigated

- Logistic Regression (LR)
- Linear Discriminant Analysis (LDA)
- K-Nearest Neighbors (KNN).
- Classification and Regression Trees (CART).
- Gaussian Naive Bayes (NB).
- Support Vector Machines (SVM).

# Logistic Regression

Is a linear model suitable for binary classification. Uses logistic function.
Logistic function which is a type of sigmoid function (s shaped function basically).

It is suitable to create two groups which makes it suitable for binary classification.

# Linear Discriminant Analysis (LDA)

LDA finds linear combinations of features that best separates data to two or more classes. It assumes that distribution of data based on similar gaussian matrix.

# K-Nearest Neighbors (KNN)

Classifies data by looking at its neighbors. Simple but successful method.

# Gaussian Naive Bayes (NB)

This method assumes features follow gaussian distribution and is useful when features are weakly correlated. Uses classifier based on bayes theorem. Bayes theorem is way to find probability of an event based on prior information. has 3 important parts
prior probability -> possibility of event A happening

likelihood -> probability of new evidence B occurs when A happens.

posterior probability -> updated probability of A after B is happened.

# Support Vector Machines (SVM)

is a supervised learning model used for classification and regression. Finds best hyperplane that separates data.
Hyperplane -> a flat hyper surface with one less dimension than its ambient space. Is a power method to handle non linear relations.
