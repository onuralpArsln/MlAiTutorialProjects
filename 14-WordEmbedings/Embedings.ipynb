{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/14-WordEmbedings/Embedings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38dc3888",
      "metadata": {
        "id": "38dc3888"
      },
      "source": [
        "Burada RAG için önemli olacak bir yapıyı inceliyoruz text içinden konu ile alakalı şeyleri bulmak için bir text yöentim sistemi\n",
        "\n",
        "Yazı → Embedding → Cosine Similarity → En alakalı içerikler → LLM'e ver → Süper tahmin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7f8390d",
      "metadata": {
        "id": "d7f8390d"
      },
      "source": [
        "# Pre-Req\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1981438e",
      "metadata": {
        "id": "1981438e"
      },
      "outputs": [],
      "source": [
        "%pip install -q sentence-transformers scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# En Basit Hafıza Modelimiz\n",
        "\n",
        "memory = Hem metin hem embedding saklıyoruz.\n",
        "\n",
        "model = Ücretsiz, hafif bir encoder.\n",
        "\n",
        "MAX_MEMORY = Hafızamız dolunca eskileri atıyoruz."
      ],
      "metadata": {
        "id": "tR1-KzVKDH6F"
      },
      "id": "tR1-KzVKDH6F"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Gerekli modülleri alalım\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# 2. Embedding modelimizi yükleyelim (çok hafif bir model)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# 3. Haber hafızamızı tutacak yer\n",
        "memory = []\n",
        "\n",
        "# 4. Sliding window kapasitesi\n",
        "MAX_MEMORY = 5  # son 5 haber tutulacak"
      ],
      "metadata": {
        "id": "0dwYA7bZDM2P"
      },
      "id": "0dwYA7bZDM2P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Haberi / Yeni Metini Kaydetme Fonksiyonu\n",
        "\n",
        "encode([text])[0] ➔ metni vektör yapıyor.\n",
        "\n",
        "memory dizisine hem metin hem embedding ekliyoruz.\n",
        "\n",
        "5'ten fazla olunca en eskisi çıkıyor ➔ SLIDING window böyle."
      ],
      "metadata": {
        "id": "YTtBJn85DYeL"
      },
      "id": "YTtBJn85DYeL"
    },
    {
      "cell_type": "code",
      "source": [
        "def add_news_to_memory(text):\n",
        "    # Haber embed ediliyor (sayılara çeviriliyor)\n",
        "    embedding = model.encode([text])[0] # vektör tek boyut\n",
        "\n",
        "    # Memory'ye kaydediyoruz\n",
        "    memory.append({\n",
        "        \"text\": text,\n",
        "        \"embedding\": embedding\n",
        "    })\n",
        "\n",
        "    # Sliding window: Hafıza dolarsa en eskiyi sil\n",
        "    if len(memory) > MAX_MEMORY:\n",
        "        memory.pop(0)\n"
      ],
      "metadata": {
        "id": "3uoZJW9MDd4r"
      },
      "id": "3uoZJW9MDd4r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# En Benzer Haberi / Metini Bulma Fonksiyonu\n",
        "\n",
        "cosine_similarity ➔ 0 ile 1 arasında benzerlik verir.\n",
        "\n",
        "1 ➔ aynı haber, 0 ➔ tamamen alakasız."
      ],
      "metadata": {
        "id": "U8jACNAzDuqg"
      },
      "id": "U8jACNAzDuqg"
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_similar_news(new_text):\n",
        "    if not memory:\n",
        "        return None\n",
        "\n",
        "    # Yeni gelen haberi embed edelim\n",
        "    new_embedding = model.encode([new_text])[0]\n",
        "\n",
        "    # Hafızadaki embeddinglerle benzerlik hesapla\n",
        "    memory_embeddings = np.array([item['embedding'] for item in memory])\n",
        "    similarities = cosine_similarity([new_embedding], memory_embeddings)[0]\n",
        "\n",
        "    # En yüksek skorlu haberi bul\n",
        "    most_similar_idx = np.argmax(similarities)\n",
        "    most_similar_text = memory[most_similar_idx]['text']\n",
        "    similarity_score = similarities[most_similar_idx]\n",
        "\n",
        "    return most_similar_text, similarity_score"
      ],
      "metadata": {
        "id": "g965H410D1oB"
      },
      "id": "g965H410D1oB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kendi Kendimize Test Edelim!"
      ],
      "metadata": {
        "id": "0Kxz5uztECBC"
      },
      "id": "0Kxz5uztECBC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hafızaya 5 haber atalım\n",
        "add_news_to_memory(\"Borsa bugün %2 arttı, yatırımcılar mutlu.\")\n",
        "add_news_to_memory(\"Merkez Bankası faiz oranlarını değiştirmedi.\")\n",
        "add_news_to_memory(\"Dolar kuru sabit kaldı, euroda küçük düşüş.\")\n",
        "add_news_to_memory(\"Altın fiyatları rekor kırdı, yatırımcılar ilgilendi.\")\n",
        "add_news_to_memory(\"Teknoloji şirketlerinde büyük işten çıkarmalar başladı.\")\n",
        "\n",
        "# Yeni haber yazalım\n",
        "new_news = \"Borsa rekor seviyeye ulaştı, yatırımcılar coşkulu.\"\n",
        "\n",
        "# En benzer eski haberi bulalım\n",
        "similar_text, score = find_most_similar_news(new_news)\n",
        "\n",
        "print(f\"\\nYeni haber: {new_news}\\n\")\n",
        "print(f\"En benzer eski haber: {similar_text}\")\n",
        "print(f\"Benzerlik skoru: {score:.2f}\")"
      ],
      "metadata": {
        "id": "c_KUOZwjEHbk"
      },
      "id": "c_KUOZwjEHbk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# En Benzer 3 Haber Bulma\n",
        "\n",
        "np.argsort(similarities)[::-1]: Benzerlikleri azalan sırayla sıraladık.\n",
        "\n",
        "Sonra, ilk 3 elemana (yani en yüksek skorlara) erişiyoruz.\n",
        "\n",
        "top_3_texts: En benzer 3 haberin metinlerini alıyoruz.\n",
        "\n",
        "top_3_scores: En benzer 3 haberin skorlarını alıyoruz."
      ],
      "metadata": {
        "id": "MycbTu4cE4Yt"
      },
      "id": "MycbTu4cE4Yt"
    },
    {
      "cell_type": "code",
      "source": [
        "def find_top_3_similar_news(new_text):\n",
        "    if not memory:\n",
        "        return None\n",
        "\n",
        "    # Yeni gelen haberi embed edelim\n",
        "    new_embedding = model.encode([new_text])[0]\n",
        "\n",
        "    # Hafızadaki embeddinglerle benzerlik hesapla\n",
        "    memory_embeddings = np.array([item['embedding'] for item in memory])\n",
        "    similarities = cosine_similarity([new_embedding], memory_embeddings)[0]\n",
        "\n",
        "    # Benzerlikleri azalan sırayla sıralayalım (en yüksek skoru en önce almak için)\n",
        "    sorted_idx = np.argsort(similarities)[::-1]\n",
        "\n",
        "    # En benzer 3 haberi ve skorları al\n",
        "    top_3_texts = []\n",
        "    top_3_scores = []\n",
        "    for idx in sorted_idx[:3]:\n",
        "        top_3_texts.append(memory[idx]['text'])\n",
        "        top_3_scores.append(similarities[idx])\n",
        "\n",
        "    return top_3_texts, top_3_scores\n"
      ],
      "metadata": {
        "id": "GEZ3K_IwE9rS"
      },
      "id": "GEZ3K_IwE9rS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yeni bir haber geldi\n",
        "new_news = \"Borsa rekor seviyeye ulaştı, yatırımcılar coşkulu.\"\n",
        "\n",
        "# En benzer 3 haberi ve skorlarını bulalım\n",
        "top_3_texts, top_3_scores = find_top_3_similar_news(new_news)\n",
        "\n",
        "# Sonuçları yazdıralım\n",
        "print(\"En benzer 3 haber ve skorları:\")\n",
        "for text, score in zip(top_3_texts, top_3_scores):\n",
        "    print(f\"- {text} (Skor: {score:.2f})\")\n"
      ],
      "metadata": {
        "id": "qaRdWAFYE_rQ"
      },
      "id": "qaRdWAFYE_rQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embed Görselleştirmesi"
      ],
      "metadata": {
        "id": "J1m9mcbrFGUa"
      },
      "id": "J1m9mcbrFGUa"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Gerekli modülleri yükle\n",
        "%pip install -q matplotlib scikit-learn"
      ],
      "metadata": {
        "id": "9qPivOWfFNcH"
      },
      "id": "9qPivOWfFNcH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. Kodlara başla\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "# Hafızamızda birkaç haber olsun (örnek verelim)\n",
        "memory = [\n",
        "    {\"text\": \"Borsa yükseldi, yatırımcılar mutlu.\", \"embedding\": model.encode([\"Borsa yükseldi, yatırımcılar mutlu.\"])[0]},\n",
        "    {\"text\": \"Merkez Bankası faiz oranlarını değiştirmedi.\", \"embedding\": model.encode([\"Merkez Bankası faiz oranlarını değiştirmedi.\"])[0]},\n",
        "    {\"text\": \"Dolar kuru sabit kaldı.\", \"embedding\": model.encode([\"Dolar kuru sabit kaldı.\"])[0]},\n",
        "    {\"text\": \"Altın fiyatları rekor kırdı.\", \"embedding\": model.encode([\"Altın fiyatları rekor kırdı.\"])[0]},\n",
        "    {\"text\": \"Teknoloji şirketlerinde işten çıkarmalar başladı.\", \"embedding\": model.encode([\"Teknoloji şirketlerinde işten çıkarmalar başladı.\"])[0]},\n",
        "]\n",
        "\n",
        "# 3. Embeddingleri toplayalım\n",
        "embeddings = np.array([item['embedding'] for item in memory])\n",
        "\n",
        "\n",
        "# 4. PCA ile 2D'ye indirelim\n",
        "pca = PCA(n_components=2)\n",
        "reduced_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "\n",
        "# 5. Grafiği çizelim\n",
        "plt.figure(figsize=(8,6))\n",
        "for idx, item in enumerate(memory):\n",
        "    x, y = reduced_embeddings[idx]\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x+0.01, y+0.01, item['text'], fontsize=9)\n",
        "\n",
        "plt.title('Haber Embeddingleri PCA ile Görselleştirme')\n",
        "plt.xlabel('PCA 1')\n",
        "plt.ylabel('PCA 2')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UuPSS5NvFGGT"
      },
      "id": "UuPSS5NvFGGT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}