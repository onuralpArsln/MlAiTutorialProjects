{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/5-ImageClass/CarPlane/imageClasser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBm_IkQ2qeF2"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gPIdEQQlw0l"
      },
      "source": [
        "# Prep\n",
        "\n",
        "Eğer colab ile açtıysan mevcut colab workspaceine data kalsörünü çekmen lazım neyseki bu çok kolay sadece ağaıdaki komutları kullan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfQaWm4vqTAD",
        "outputId": "3f031293-cce3-4190-aa59-8f16f186daa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-27 18:41:39--  https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/5-ImageClass/CarPlane/data.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/onuralpArsln/MlAiTutorialProjects/main/5-ImageClass/CarPlane/data.zip [following]\n",
            "--2025-01-27 18:41:40--  https://raw.githubusercontent.com/onuralpArsln/MlAiTutorialProjects/main/5-ImageClass/CarPlane/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4850435 (4.6M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   4.62M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-01-27 18:41:40 (38.6 MB/s) - ‘data.zip’ saved [4850435/4850435]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/5-ImageClass/CarPlane/data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7rm0IMYzbUk"
      },
      "source": [
        "-q makes it quiet or else it will print 500 file name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-ZBDXh0In4Ps"
      },
      "outputs": [],
      "source": [
        "!unzip -q data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bMC2-Wbln32"
      },
      "source": [
        "# Classification Model With Keras\n",
        "\n",
        "\n",
        "Bu çalışmada Keras kullanarak bir sınıflandırma yapacağız.\n",
        "\n",
        "Data klasörü içine bakarak kullanacağımız görsellere bakabilirsin.\n",
        "\n",
        "Toplamda 500 adet görsel mevcuttur.\n",
        "\n",
        "\n",
        "200 uçak ve 200 araba görseli modeli eğitmek için 50 uçak ve 50 araba görseli modeli test etmek için kullanılacak.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVRy6kHYln37"
      },
      "outputs": [],
      "source": [
        "# keras versiyonuna göre yorum bu altaki iki importtan birini yapman gerekebilir\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# keras versiyonuna göre yorum bu yukardaki iki importtan birini yapman\n",
        "# yorum satırını değiştirmeyi dene hata alırsan\n",
        "\n",
        "       \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "img_width, img_height = 224, 224\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nRoNAGcln39"
      },
      "source": [
        "görüntüler 224 pixele 224 pixel. Sınıflandırma için süper hd bir görüntüye gerek yok. Görüntülerde hızlıca çalışmak sınıflandırma için daha verimli olacak.\n",
        "\n",
        "değişkenlerimize bilgileri atıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WaQIUgmUln3-"
      },
      "outputs": [],
      "source": [
        "train_data_dir = 'data/train'\n",
        "validation_data_dir = 'data/test'\n",
        "nb_train_samples =400\n",
        "nb_validation_samples = 100\n",
        "epochs = 10\n",
        "batch_size = 16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "610Z9w_8ln3-"
      },
      "source": [
        "Epoch ve Batch_size önemli kavramlar  \n",
        "\n",
        "Epoch basitçe veri seti üzerinde kça iterasyon yapılacağını ifade eder\n",
        "\n",
        "Batch size ise bir seferde incelenecek örnek sayısını ifade eder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NRnq60Isln3_"
      },
      "outputs": [],
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "\tinput_shape = (3, img_width, img_height)\n",
        "else:\n",
        "\tinput_shape = (img_width, img_height, 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p3NgnZFln3_"
      },
      "source": [
        "Burada amaç veri formatının düzgün aktarılmasından emin olmak. Channels Rgb kanalları, eğer rgb kanalları ilk yazılır ise önce kanal sonra boyut verilir. Aksi halde önce boyut sonra kanal ifade ediliyor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLogoyXsln3_",
        "outputId": "36a38ebc-64f0-4812-de1f-68e70ae70b2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDmrdY0Yln4A"
      },
      "source": [
        "Burada aslında ağ mimarisini yazdık. daha ileri seviye çalışmalar için mevcut başarılı mimariler kullanmak güzeldir ama ne olduğu görmek için önemli bi adım    \n",
        "\n",
        "\n",
        "\n",
        "Conv2D , görüntüyü birden fazla görüntüye evriştiren katmandır.\n",
        "\n",
        "\n",
        "Aktivasyon , aktivasyon fonksiyonudur.\n",
        "MaxPooling2D, verilen boyut matrisindeki değeri maksimuma çıkarmak için kullanılır ve aynısı sonraki 2 katman için kullanılır. daha sonra Düzleştir , evriştirildikten sonra elde edilen görüntünün boyutlarını düzleştirmek için kullanılır.\n",
        "Yoğun, bunu tamamen bağlantılı bir model haline getirmek için kullanılır ve gizli katmandır.\n",
        "Bırakma, veri kümesine aşırı sığmayı önlemek için kullanılır.\n",
        "Yoğun, çıktı katmanının görüntünün hangi kategoriye ait olduğuna karar veren yalnızca bir nöron içermesidir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xb9a3CEDln4A"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "\t\t\toptimizer='rmsprop',\n",
        "\t\t\tmetrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHzEdpRdln4B"
      },
      "source": [
        "Burada kayıp, optimize ediciler ve metriklerin kullanımını içeren derleme işlevi kullanılmıştır. Burada kullanılan kayıp fonksiyonu Binary_crossentropy, kullanılan optimizer ise rmsprop'tur ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZXc1j2Bln4B",
        "outputId": "a4b90a73-22fe-465a-cf98-bd5ff31b3568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n"
          ]
        }
      ],
      "source": [
        "# eğer aşağıda pil ile ilgili hata alaırsan bunu kullan\n",
        "!pip3 install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svcKTMHGln4C",
        "outputId": "bd268808-68f0-475a-fdb0-343bdb697a71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from PIL import Image\n",
        "sys.modules['Image'] = Image\n",
        "from PIL import Image\n",
        "print(Image.__file__)\n",
        "import Image\n",
        "print(Image.__file__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixV_P4Mqln4C",
        "outputId": "505df90b-a70b-49be-b16f-3d08cba16aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 996ms/step - accuracy: 0.5079 - loss: 0.9222 - val_accuracy: 0.8438 - val_loss: 0.5608\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.5830\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 981ms/step - accuracy: 0.6937 - loss: 0.6239 - val_accuracy: 0.8229 - val_loss: 0.3455\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 0.6329\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 917ms/step - accuracy: 0.7378 - loss: 0.5640 - val_accuracy: 0.7917 - val_loss: 0.4290\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.7877\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 957ms/step - accuracy: 0.7492 - loss: 0.4602 - val_accuracy: 0.8646 - val_loss: 0.2718\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.7688\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 957ms/step - accuracy: 0.8258 - loss: 0.4154 - val_accuracy: 0.8438 - val_loss: 0.3975\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.2500 - val_loss: 1.1424\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b07d7edde10>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "\trescale=1. / 255,\n",
        "\tshear_range=0.2,\n",
        "\tzoom_range=0.2,\n",
        "\thorizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\ttrain_data_dir,\n",
        "\ttarget_size=(img_width, img_height),\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "\tvalidation_data_dir,\n",
        "\ttarget_size=(img_width, img_height),\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "model.fit(\n",
        "\ttrain_generator,\n",
        "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
        "\tepochs=epochs,\n",
        "\tvalidation_data=validation_generator,\n",
        "\tvalidation_steps=nb_validation_samples // batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1iu-9KBln4C"
      },
      "source": [
        "Şimdi dataGenerator'ın kısmı devreye giriyor. Hangisinde kullandık:\n",
        "\n",
        "Görüntüyü yeniden ölçeklendiren, belirli bir aralıkta kesme uygulayan, görüntüyü yakınlaştıran ve görüntüyle yatay çevirme yapan ImageDataGenerator . Bu ImageDataGenerator görüntünün tüm olası yönelimlerini içerir.\n",
        "train_datagen.flow_from_directory, train_dataset dizininden veri hazırlamak için kullanılan işlevdir Target_size, görüntünün hedef boyutunu belirtir.\n",
        "test_datagen.flow_from_directory , model için test verilerini hazırlamak için kullanılır ve hepsi yukarıdakine benzer.\n",
        "fit_generator, verileri yukarıda yapılan modele sığdırmak için kullanılır; kullanılan diğer faktörler,step_per_epochs'tur ve bize modelin eğitim verileri için kaç kez yürütüleceğini bildirir.\n",
        "Epochs bize modelin ileri ve geri geçişte kaç kez eğitileceğini söyler.\n",
        "validation_data, doğrulama/test verilerini modele beslemek için kullanılır.\n",
        "validation_steps doğrulama/test örneklerinin sayısını belirtir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpIf5m64ln4D",
        "outputId": "ed6cc70a-7d7f-4ced-a7d0-5c259d7794ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('model_saved.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOoyQSnsln4D",
        "outputId": "89e8ff92-f796-41d3-8326-4740b703058f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
            "Predicted Class (0 - Cars , 1- Planes):  0.9849878\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('model_saved.h5')\n",
        "\n",
        "image = load_img('/content/data/test/planes/10.jpg', target_size=(224, 224))\n",
        "img = np.array(image)\n",
        "img = img / 255.0\n",
        "img = img.reshape(1,224,224,3)\n",
        "label = model.predict(img)\n",
        "print(\"Predicted Class (0 - Cars , 1- Planes): \", label[0][0])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "imageClasser.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
