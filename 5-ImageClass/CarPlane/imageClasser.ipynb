{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/5-ImageClass/CarPlane/imageClasser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WBm_IkQ2qeF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep\n",
        "\n",
        "Eğer colab ile açtıysan mevcut colab workspaceine data kalsörünü çekmen lazım neyseki bu çok kolay sadece ağaıdaki komutları kullan"
      ],
      "metadata": {
        "id": "6gPIdEQQlw0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/ImageClass/CarPlane/data.zip"
      ],
      "metadata": {
        "id": "nfQaWm4vqTAD",
        "outputId": "6a0657e7-1e41-4863-ce6b-fda9705fd06b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-16 13:11:33--  https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/ImageClass/CarPlane/data.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/onuralpArsln/MlAiTutorialProjects/main/ImageClass/CarPlane/data.zip [following]\n",
            "--2024-07-16 13:11:34--  https://raw.githubusercontent.com/onuralpArsln/MlAiTutorialProjects/main/ImageClass/CarPlane/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4850435 (4.6M) [application/zip]\n",
            "Saving to: ‘data.zip.1’\n",
            "\n",
            "data.zip.1          100%[===================>]   4.62M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-07-16 13:11:34 (177 MB/s) - ‘data.zip.1’ saved [4850435/4850435]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-q makes it quiet or else it will print 500 file name"
      ],
      "metadata": {
        "id": "X7rm0IMYzbUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q data.zip"
      ],
      "metadata": {
        "id": "-ZBDXh0In4Ps",
        "outputId": "35418320-3855-464c-a4b5-e114e920eb1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace data/test/cars/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bMC2-Wbln32"
      },
      "source": [
        "# Classification Model With Keras\n",
        "\n",
        "\n",
        "Bu çalışmada Keras kullanarak bir sınıflandırma yapacağız.\n",
        "\n",
        "Data klasörü içine bakarak kullanacağımız görsellere bakabilirsin.\n",
        "\n",
        "Toplamda 500 adet görsel mevcuttur.\n",
        "\n",
        "\n",
        "200 uçak ve 200 araba görseli modeli eğitmek için 50 uçak ve 50 araba görseli modeli test etmek için kullanılacak.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVRy6kHYln37"
      },
      "outputs": [],
      "source": [
        "# keras versiyonuna göre yorum bu altaki iki importtan birini yapman gerekebilir\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# keras versiyonuna göre yorum bu yukardaki iki importtan birini yapman\n",
        "# yorum satırını değiştirmeyi dene hata alırsan\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "img_width, img_height = 224, 224\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nRoNAGcln39"
      },
      "source": [
        "görüntüler 224 pixele 224 pixel. Sınıflandırma için süper hd bir görüntüye gerek yok. Görüntülerde hızlıca çalışmak sınıflandırma için daha verimli olacak.\n",
        "\n",
        "değişkenlerimize bilgileri atıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaQIUgmUln3-"
      },
      "outputs": [],
      "source": [
        "train_data_dir = 'data/train'\n",
        "validation_data_dir = 'data/test'\n",
        "nb_train_samples =400\n",
        "nb_validation_samples = 100\n",
        "epochs = 10\n",
        "batch_size = 16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "610Z9w_8ln3-"
      },
      "source": [
        "Epoch ve Batch_size önemli kavramlar  \n",
        "\n",
        "Epoch basitçe veri seti üzerinde kça iterasyon yapılacağını ifade eder\n",
        "\n",
        "Batch size ise bir seferde incelenecek örnek sayısını ifade eder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRnq60Isln3_"
      },
      "outputs": [],
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "\tinput_shape = (3, img_width, img_height)\n",
        "else:\n",
        "\tinput_shape = (img_width, img_height, 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p3NgnZFln3_"
      },
      "source": [
        "Burada amaç veri formatının düzgün aktarılmasından emin olmak. Channels Rgb kanalları, eğer rgb kanalları ilk yazılır ise önce kanal sonra boyut verilir. Aksi halde önce boyut sonra kanal ifade ediliyor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLogoyXsln3_"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDmrdY0Yln4A"
      },
      "source": [
        "Burada aslında ağ mimarisini yazdık. daha ileri seviye çalışmalar için mevcut başarılı mimariler kullanmak güzeldir ama ne olduğu görmek için önemli bi adım    \n",
        "\n",
        "\n",
        "\n",
        "Conv2D , görüntüyü birden fazla görüntüye evriştiren katmandır.\n",
        "\n",
        "\n",
        "Aktivasyon , aktivasyon fonksiyonudur.\n",
        "MaxPooling2D, verilen boyut matrisindeki değeri maksimuma çıkarmak için kullanılır ve aynısı sonraki 2 katman için kullanılır. daha sonra Düzleştir , evriştirildikten sonra elde edilen görüntünün boyutlarını düzleştirmek için kullanılır.\n",
        "Yoğun, bunu tamamen bağlantılı bir model haline getirmek için kullanılır ve gizli katmandır.\n",
        "Bırakma, veri kümesine aşırı sığmayı önlemek için kullanılır.\n",
        "Yoğun, çıktı katmanının görüntünün hangi kategoriye ait olduğuna karar veren yalnızca bir nöron içermesidir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb9a3CEDln4A"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "\t\t\toptimizer='rmsprop',\n",
        "\t\t\tmetrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHzEdpRdln4B"
      },
      "source": [
        "Burada kayıp, optimize ediciler ve metriklerin kullanımını içeren derleme işlevi kullanılmıştır. Burada kullanılan kayıp fonksiyonu Binary_crossentropy, kullanılan optimizer ise rmsprop'tur ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZXc1j2Bln4B",
        "outputId": "9334b5ef-efe7-4417-bb15-9fa9170532c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "# eğer aşağıda pil ile ilgili hata alaırsan bunu kullan\n",
        "!pip3 install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svcKTMHGln4C",
        "outputId": "00d6e80f-7a44-45a1-aa83-4ecfc94b0417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from PIL import Image\n",
        "sys.modules['Image'] = Image\n",
        "from PIL import Image\n",
        "print(Image.__file__)\n",
        "import Image\n",
        "print(Image.__file__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixV_P4Mqln4C",
        "outputId": "b75a56a2-2dd3-409e-bb50-f545ac3af8b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400 images belonging to 2 classes.\n",
            "Found 100 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 39s 1s/step - loss: 0.7017 - accuracy: 0.5725 - val_loss: 0.5826 - val_accuracy: 0.5625\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 23s 920ms/step - loss: 0.5191 - accuracy: 0.7550 - val_loss: 0.3350 - val_accuracy: 0.8438\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 22s 860ms/step - loss: 0.4782 - accuracy: 0.7975 - val_loss: 0.2765 - val_accuracy: 0.9062\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 23s 891ms/step - loss: 0.4231 - accuracy: 0.8250 - val_loss: 0.3546 - val_accuracy: 0.8333\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 24s 953ms/step - loss: 0.3259 - accuracy: 0.8500 - val_loss: 0.2953 - val_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 23s 924ms/step - loss: 0.3815 - accuracy: 0.8425 - val_loss: 0.2989 - val_accuracy: 0.8542\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 29s 1s/step - loss: 0.3460 - accuracy: 0.8650 - val_loss: 0.2720 - val_accuracy: 0.8750\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 22s 866ms/step - loss: 0.3369 - accuracy: 0.8525 - val_loss: 0.2344 - val_accuracy: 0.9062\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 24s 903ms/step - loss: 0.2944 - accuracy: 0.8825 - val_loss: 0.3080 - val_accuracy: 0.8542\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 24s 933ms/step - loss: 0.2713 - accuracy: 0.8950 - val_loss: 0.3013 - val_accuracy: 0.8542\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b72c4a4b520>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "\trescale=1. / 255,\n",
        "\tshear_range=0.2,\n",
        "\tzoom_range=0.2,\n",
        "\thorizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\ttrain_data_dir,\n",
        "\ttarget_size=(img_width, img_height),\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "\tvalidation_data_dir,\n",
        "\ttarget_size=(img_width, img_height),\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "model.fit(\n",
        "\ttrain_generator,\n",
        "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
        "\tepochs=epochs,\n",
        "\tvalidation_data=validation_generator,\n",
        "\tvalidation_steps=nb_validation_samples // batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1iu-9KBln4C"
      },
      "source": [
        "Şimdi dataGenerator'ın kısmı devreye giriyor. Hangisinde kullandık:\n",
        "\n",
        "Görüntüyü yeniden ölçeklendiren, belirli bir aralıkta kesme uygulayan, görüntüyü yakınlaştıran ve görüntüyle yatay çevirme yapan ImageDataGenerator . Bu ImageDataGenerator görüntünün tüm olası yönelimlerini içerir.\n",
        "train_datagen.flow_from_directory, train_dataset dizininden veri hazırlamak için kullanılan işlevdir Target_size, görüntünün hedef boyutunu belirtir.\n",
        "test_datagen.flow_from_directory , model için test verilerini hazırlamak için kullanılır ve hepsi yukarıdakine benzer.\n",
        "fit_generator, verileri yukarıda yapılan modele sığdırmak için kullanılır; kullanılan diğer faktörler,step_per_epochs'tur ve bize modelin eğitim verileri için kaç kez yürütüleceğini bildirir.\n",
        "Epochs bize modelin ileri ve geri geçişte kaç kez eğitileceğini söyler.\n",
        "validation_data, doğrulama/test verilerini modele beslemek için kullanılır.\n",
        "validation_steps doğrulama/test örneklerinin sayısını belirtir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpIf5m64ln4D",
        "outputId": "3f47aa7c-28e2-44b9-82ad-818ccf935655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('model_saved.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOoyQSnsln4D",
        "outputId": "24ef0504-c5c5-4483-afb8-590e9d1826e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 126ms/step\n",
            "Predicted Class (0 - Cars , 1- Planes):  0.8610517\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('model_saved.h5')\n",
        "\n",
        "image = load_img('data/test/planes/5.jpg', target_size=(224, 224))\n",
        "img = np.array(image)\n",
        "img = img / 255.0\n",
        "img = img.reshape(1,224,224,3)\n",
        "label = model.predict(img)\n",
        "print(\"Predicted Class (0 - Cars , 1- Planes): \", label[0][0])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "name": "imageClasser.ipynb",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}