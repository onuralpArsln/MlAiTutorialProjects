{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/5-ImageClass/ArchitecturesAdv/architec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e90e5064",
      "metadata": {
        "id": "e90e5064"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/5-ImageClass/ArchitecturesAdv/architec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "106b1df9",
      "metadata": {
        "id": "106b1df9"
      },
      "source": [
        "### Githubdan data indir\n",
        "\n",
        "Bu dataset kaggledan alınmış FER 2013 challenge datasıdır.  modelleri zorladığı için kullanması keyifli\n",
        "\n",
        "https://www.kaggle.com/datasets/msambare/fer2013?resource=download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9616182d",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "9616182d"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/5-ImageClass/Fer2013Kaggle.zip -q -O data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "75914368",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75914368",
        "outputId": "a97d5d0b-2a8e-4f62-b73c-c51902ac59f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace test/angry/PrivateTest_10131363.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip -q data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install visualkeras"
      ],
      "metadata": {
        "id": "GS02FZdD2Yyv"
      },
      "id": "GS02FZdD2Yyv",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f46225e2",
      "metadata": {
        "id": "f46225e2"
      },
      "source": [
        "Python ile hızlıca datayı eğitim için hazırla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "7baaa94d",
      "metadata": {
        "id": "7baaa94d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "# 📂 Dataset ana klasörleri\n",
        "test_dir = 'test'   # test/angry, test/disgust, test/fear ...\n",
        "train_dir = 'train' # train/angry, train/disgust, train/fear ...\n",
        "\n",
        "# 📌 Görselleri yükleyen fonksiyon (48x48 dataset için)\n",
        "def load_images_from_directory(base_dir, label, img_size=(48, 48), limit=90000):\n",
        "    images = []\n",
        "    labels = []\n",
        "    count = 0\n",
        "    for file_name in os.listdir(base_dir):\n",
        "        if count >= limit:  # 300'den sonra dur\n",
        "            break\n",
        "        if file_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "            file_path = os.path.join(base_dir, file_name)\n",
        "            # grayscale yaptık çünkü kaynak grayscale\n",
        "            img = tf.keras.preprocessing.image.load_img(file_path, target_size=img_size, color_mode=\"grayscale\")\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0  # normalize\n",
        "            images.append(img_array)\n",
        "            labels.append(label)\n",
        "            count += 1\n",
        "    return images, labels\n",
        "\n",
        "# Duygu klasörleri ve etiketleri\n",
        "emotion_dirs = {\n",
        "    \"angry\": 0,\n",
        "    \"disgust\": 1,\n",
        "    \"fear\": 2,\n",
        "    \"happy\": 3,\n",
        "    \"neutral\": 4,\n",
        "    \"surprise\": 5,\n",
        "    \"sad\": 6\n",
        "}\n",
        "\n",
        "# --- Train verisi ---\n",
        "train_images, train_labels = [], []\n",
        "for emotion, label in emotion_dirs.items():\n",
        "    img_dir = os.path.join(train_dir, emotion)\n",
        "    images, labels = load_images_from_directory(img_dir, label=label)\n",
        "    train_images.extend(images)\n",
        "    train_labels.extend(labels)\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# --- Test verisi ---\n",
        "test_images, test_labels = [], []\n",
        "for emotion, label in emotion_dirs.items():\n",
        "    img_dir = os.path.join(test_dir, emotion)\n",
        "    images, labels = load_images_from_directory(img_dir, label=label)\n",
        "    test_images.extend(images)\n",
        "    test_labels.extend(labels)\n",
        "\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "\n",
        "X_train, y_train = train_images, train_labels\n",
        "X_test, y_test = test_images, test_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5be808c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5be808c3",
        "outputId": "ed1978e4-df14-4cdf-9336-f85a8a454f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elindeki veri miktarı ve test train dağlımı\n",
            "X_train shape: (28709, 48, 48, 1)\n",
            "X_test shape: (7178, 48, 48, 1)\n",
            "y_train shape: (28709,)\n",
            "y_test shape: (7178,)\n",
            "Train samples: 28709\n",
            "Test samples: 7178\n"
          ]
        }
      ],
      "source": [
        "print(\"Elindeki veri miktarı ve test train dağlımı\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "print(\"Train samples:\", len(X_train))\n",
        "print(\"Test samples:\", len(X_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Functions"
      ],
      "metadata": {
        "id": "wsp0pRP21wIP"
      },
      "id": "wsp0pRP21wIP"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
        "\n",
        "def compile_and_train(model, name, epochs=5, batch_size=64):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    start = time.time()\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        verbose=1)\n",
        "    end = time.time()\n",
        "    plot_model(model, to_file=f\"{name}.png\", show_shapes=True, dpi=80)\n",
        "    print(f\"{name} trained in {(end-start):.2f}s\")\n",
        "    return model, history\n",
        "\n",
        "def get_flops(model):\n",
        "    concrete = tf.function(lambda inputs: model(inputs))\n",
        "    concrete_func = concrete.get_concrete_function(tf.TensorSpec([1,*model.input.shape[1:]]))\n",
        "    frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
        "    graph = frozen_func.graph.as_graph_def()\n",
        "    run_meta = tf.compat.v1.RunMetadata()\n",
        "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "    flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd='op', options=opts)\n",
        "    return flops.total_float_ops\n"
      ],
      "metadata": {
        "id": "SHl02fsY1zJe"
      },
      "id": "SHl02fsY1zJe",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN\n"
      ],
      "metadata": {
        "id": "dj6P-ScV110M"
      },
      "id": "dj6P-ScV110M"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn(input_shape=(48,48,1), num_classes=7):\n",
        "    return models.Sequential([\n",
        "        layers.Conv2D(32,3,activation='relu',input_shape=input_shape),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64,3,activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128,3,activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128,activation='relu'),\n",
        "        layers.Dense(num_classes,activation='softmax')\n",
        "    ])\n",
        "\n",
        "cnn_model = build_cnn()\n",
        "\n",
        "# Summary\n",
        "cnn_model.summary()\n",
        "tf.keras.utils.plot_model(cnn_model, to_file=\"model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Plot model architecture\n",
        "tf.keras.utils.plot_model(\n",
        "    cnn_model, to_file=\"cnn_model.png\",\n",
        "    show_shapes=True, show_layer_names=True, dpi=80\n",
        ")\n",
        "\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "visualkeras.layered_view(cnn_model, legend=True, to_file=\"cnn_visual.png\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "3LPiMMLw11kw",
        "outputId": "6aa8b0ba-e8f1-4b6a-cc7b-765cd35f7a47"
      },
      "id": "3LPiMMLw11kw",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,048,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,142,279\u001b[0m (4.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,142,279</span> (4.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,142,279\u001b[0m (4.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,142,279</span> (4.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/visualkeras/layered.py:86: UserWarning: The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\n",
            "  warnings.warn(\"The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=664x284>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "cnn, hist_cnn = compile_and_train(build_cnn(), \"CNN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCbdRvSb3lBl",
        "outputId": "c6b32d7b-917a-4d4e-e56c-84ded688dbe0"
      },
      "id": "YCbdRvSb3lBl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m229/449\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:08\u001b[0m 312ms/step - accuracy: 0.2668 - loss: 1.8025"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet"
      ],
      "metadata": {
        "id": "moaLHumA3kyK"
      },
      "id": "moaLHumA3kyK"
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, stride=1):\n",
        "    shortcut = x\n",
        "    x = layers.Conv2D(filters,3,padding='same',strides=stride)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(filters,3,padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    if stride!=1 or shortcut.shape[-1]!=filters:\n",
        "        shortcut = layers.Conv2D(filters,1,strides=stride,padding='same')(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "    x = layers.add([x,shortcut])\n",
        "    return layers.ReLU()(x)\n",
        "\n",
        "def build_resnet(input_shape=(48,48,1), num_classes=7):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32,3,padding='same',activation='relu')(inp)\n",
        "    x = residual_block(x,32)\n",
        "    x = residual_block(x,64,stride=2)\n",
        "    x = residual_block(x,128,stride=2)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    out = layers.Dense(num_classes,activation='softmax')(x)\n",
        "    return models.Model(inp,out)\n",
        "\n",
        "resnet_model = build_resnet()\n",
        "\n",
        "# Summary\n",
        "resnet_model.summary()\n",
        "\n",
        "# Keras plot\n",
        "tf.keras.utils.plot_model(resnet_model, to_file=\"resnet_model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Visualkeras layered view\n",
        "visualkeras.layered_view(resnet_model, legend=True, to_file=\"resnet_visual.png\")\n"
      ],
      "metadata": {
        "id": "dM0Kx5V536Ah"
      },
      "id": "dM0Kx5V536Ah",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "resnet, hist_resnet = compile_and_train(resnet_model, \"ResNet\")\n"
      ],
      "metadata": {
        "id": "W1orCBHq37vm"
      },
      "id": "W1orCBHq37vm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNet"
      ],
      "metadata": {
        "id": "0VMwaelP4iJN"
      },
      "id": "0VMwaelP4iJN"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "def build_densenet(input_shape=(48,48,1), num_classes=7):\n",
        "    base = DenseNet121(weights=None, include_top=False, input_shape=input_shape)\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return models.Model(base.input, out)\n",
        "\n",
        "densenet_model = build_densenet()\n",
        "\n",
        "# Summary\n",
        "densenet_model.summary()\n",
        "\n",
        "# Keras plot\n",
        "tf.keras.utils.plot_model(densenet_model, to_file=\"densenet_model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Visualkeras layered view\n",
        "visualkeras.layered_view(densenet_model, legend=True, to_file=\"densenet_visual.png\")\n"
      ],
      "metadata": {
        "id": "HIhYoGS44kxe"
      },
      "id": "HIhYoGS44kxe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "densenet, hist_densenet = compile_and_train(densenet_model, \"DenseNet\")\n"
      ],
      "metadata": {
        "id": "IMO329Ca4o7p"
      },
      "id": "IMO329Ca4o7p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EfficientNet"
      ],
      "metadata": {
        "id": "jiuSHPnQ4snV"
      },
      "id": "jiuSHPnQ4snV"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "def build_efficientnet(input_shape=(48,48,1), num_classes=7):\n",
        "    base = EfficientNetB0(weights=None, include_top=False, input_shape=input_shape)\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return models.Model(base.input, out)\n",
        "\n",
        "efficientnet_model = build_efficientnet()\n",
        "\n",
        "# Summary\n",
        "efficientnet_model.summary()\n",
        "\n",
        "# Keras plot\n",
        "tf.keras.utils.plot_model(efficientnet_model, to_file=\"efficientnet_model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Visualkeras layered view\n",
        "visualkeras.layered_view(efficientnet_model, legend=True, to_file=\"efficientnet_visual.png\")\n"
      ],
      "metadata": {
        "id": "Was9Yy5Q4wqp"
      },
      "id": "Was9Yy5Q4wqp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "efficientnet, hist_eff = compile_and_train(efficientnet_model, \"EfficientNet\")\n"
      ],
      "metadata": {
        "id": "mzsduLzv41je"
      },
      "id": "mzsduLzv41je",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN + SE (Attention)"
      ],
      "metadata": {
        "id": "HoLDV4CX47rq"
      },
      "id": "HoLDV4CX47rq"
    },
    {
      "cell_type": "code",
      "source": [
        "def se_block(x, ratio=8):\n",
        "    f = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(f//ratio,activation='relu')(se)\n",
        "    se = layers.Dense(f,activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1,1,f))(se)\n",
        "    return layers.multiply([x,se])\n",
        "\n",
        "def build_cnn_se(input_shape=(48,48,1), num_classes=7):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32,3,activation='relu',padding='same')(inp)\n",
        "    x = se_block(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64,3,activation='relu',padding='same')(x)\n",
        "    x = se_block(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    out = layers.Dense(num_classes,activation='softmax')(x)\n",
        "    return models.Model(inp,out)\n",
        "\n",
        "cnn_se_model = build_cnn_se()\n",
        "\n",
        "# Summary\n",
        "cnn_se_model.summary()\n",
        "\n",
        "# Keras plot\n",
        "tf.keras.utils.plot_model(cnn_se_model, to_file=\"cnn_se_model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Visualkeras layered view\n",
        "visualkeras.layered_view(cnn_se_model, legend=True, to_file=\"cnn_se_visual.png\")\n"
      ],
      "metadata": {
        "id": "Gyyr002l46Yb"
      },
      "id": "Gyyr002l46Yb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "cnn_se, hist_se = compile_and_train(cnn_se_model, \"CNN-SE\")\n"
      ],
      "metadata": {
        "id": "staCWiU05Ce1"
      },
      "id": "staCWiU05Ce1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vision Transformer"
      ],
      "metadata": {
        "id": "hLqfy_dP5Gl7"
      },
      "id": "hLqfy_dP5Gl7"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vit(input_shape=(48,48,1), num_classes=7,\n",
        "              patch_size=6, num_heads=4, proj_dim=64, layers_num=2):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(3,1)(inp)  # convert grayscale -> 3 channels\n",
        "    patches = layers.Conv2D(proj_dim, patch_size, strides=patch_size)(x)\n",
        "    patches = layers.Reshape((-1,proj_dim))(patches)\n",
        "    positions = tf.range(start=0, limit=patches.shape[1], delta=1)\n",
        "    pos_emb = layers.Embedding(input_dim=patches.shape[1], output_dim=proj_dim)(positions)\n",
        "    x = patches + pos_emb\n",
        "    for _ in range(layers_num):\n",
        "        attn = layers.MultiHeadAttention(num_heads=num_heads,key_dim=proj_dim)(x,x)\n",
        "        x = layers.Add()([x,attn])\n",
        "        x = layers.LayerNormalization()(x)\n",
        "        mlp = models.Sequential([layers.Dense(proj_dim*2,activation='relu'),\n",
        "                                 layers.Dense(proj_dim)])\n",
        "        x = layers.Add()([x,mlp(x)])\n",
        "        x = layers.LayerNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    out = layers.Dense(num_classes,activation='softmax')(x)\n",
        "    return models.Model(inp,out)\n",
        "\n",
        "vit_model = build_vit()\n",
        "\n",
        "# Summary\n",
        "vit_model.summary()\n",
        "\n",
        "# Keras plot\n",
        "tf.keras.utils.plot_model(vit_model, to_file=\"vit_model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Visualkeras layered view\n",
        "visualkeras.layered_view(vit_model, legend=True, to_file=\"vit_visual.png\")\n"
      ],
      "metadata": {
        "id": "mQTrK9wo5GFr"
      },
      "id": "mQTrK9wo5GFr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "vit, hist_vit = compile_and_train(vit_model, \"ViT\")"
      ],
      "metadata": {
        "id": "z8n_PPpX5MHC"
      },
      "id": "z8n_PPpX5MHC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare Models"
      ],
      "metadata": {
        "id": "LBV4U1VD5dqE"
      },
      "id": "LBV4U1VD5dqE"
    },
    {
      "cell_type": "code",
      "source": [
        "histories = {\n",
        "    \"CNN\": hist_cnn,\n",
        "    \"ResNet\": hist_resnet,\n",
        "    \"DenseNet\": hist_densenet,\n",
        "    \"EfficientNet\": hist_eff,\n",
        "    \"CNN+SE\": hist_se,\n",
        "    \"ViT\": hist_vit\n",
        "}\n",
        "models_dict = {\n",
        "    \"CNN\": cnn,\n",
        "    \"ResNet\": resnet,\n",
        "    \"DenseNet\": densenet,\n",
        "    \"EfficientNet\": efficientnet,\n",
        "    \"CNN+SE\": cnn_se,\n",
        "    \"ViT\": vit\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "for name,h in histories.items():\n",
        "    plt.plot(h.history['val_accuracy'], label=name)\n",
        "plt.legend(); plt.xlabel(\"Epochs\"); plt.ylabel(\"Val Acc\")\n",
        "plt.title(\"FER Model Zoo Comparison\")\n",
        "plt.show()\n",
        "\n",
        "for name,m in models_dict.items():\n",
        "    print(f\"{name}: Params={m.count_params():,}, FLOPs≈{get_flops(m):,}\")\n"
      ],
      "metadata": {
        "id": "71Acgt_G5hg2"
      },
      "id": "71Acgt_G5hg2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Predictions"
      ],
      "metadata": {
        "id": "EyfnjFbT52sH"
      },
      "id": "EyfnjFbT52sH"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_random_predictions(models_dict, X, y, num_images=5):\n",
        "    idxs = random.sample(range(len(X)), num_images)\n",
        "    fig, axes = plt.subplots(num_images, len(models_dict)+1, figsize=(15,3*num_images))\n",
        "    for i, idx in enumerate(idxs):\n",
        "        img, true_label = X[idx], emotion_labels[y[idx]]\n",
        "        axes[i,0].imshow(img.squeeze(), cmap='gray')\n",
        "        axes[i,0].set_title(f\"True: {true_label}\")\n",
        "        axes[i,0].axis(\"off\")\n",
        "        for j,(name,model) in enumerate(models_dict.items(),start=1):\n",
        "            pred = model.predict(img[np.newaxis,...], verbose=0)\n",
        "            pred_label = emotion_labels[np.argmax(pred)]\n",
        "            axes[i,j].imshow(img.squeeze(), cmap='gray')\n",
        "            axes[i,j].set_title(f\"{name}: {pred_label}\")\n",
        "            axes[i,j].axis(\"off\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "show_random_predictions(models_dict, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "uEMZh8kQ549s"
      },
      "id": "uEMZh8kQ549s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test on your Image"
      ],
      "metadata": {
        "id": "k0kuk__l57eu"
      },
      "id": "k0kuk__l57eu"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_custom(models_dict, filepath, target_size=(48,48)):\n",
        "    img = image.load_img(filepath, target_size=target_size, color_mode=\"grayscale\")\n",
        "    arr = image.img_to_array(img)/255.0\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    plt.imshow(arr[0].squeeze(), cmap='gray')\n",
        "    plt.axis(\"off\"); plt.title(\"Custom image\"); plt.show()\n",
        "    for name, model in models_dict.items():\n",
        "        pred = model.predict(arr, verbose=0)\n",
        "        print(f\"{name}: {emotion_labels[np.argmax(pred)]}\")\n",
        "\n",
        "# Example:\n",
        "# predict_custom(models_dict, \"my_face.png\")\n"
      ],
      "metadata": {
        "id": "szO4eMp05-gc"
      },
      "id": "szO4eMp05-gc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}