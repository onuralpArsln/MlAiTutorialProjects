{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/5-ImageClass/ArchitecturesAdv/architec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e90e5064",
      "metadata": {
        "id": "e90e5064"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/5-ImageClass/ArchitecturesAdv/architec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "106b1df9",
      "metadata": {
        "id": "106b1df9"
      },
      "source": [
        "### Githubdan data indir\n",
        "\n",
        "Bu dataset kaggledan alÄ±nmÄ±ÅŸ FER 2013 challenge datasÄ±dÄ±r.  modelleri zorladÄ±ÄŸÄ± iÃ§in kullanmasÄ± keyifli\n",
        "\n",
        "https://www.kaggle.com/datasets/msambare/fer2013?resource=download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9616182d",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "9616182d"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/5-ImageClass/Fer2013Kaggle.zip -q -O data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75914368",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "75914368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca51bc6-7cbb-4e15-fcef-32a1f5d5501b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace test/angry/PrivateTest_10131363.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip -q data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install visualkeras\n",
        "!pip -q install graphviz pydot"
      ],
      "metadata": {
        "id": "GS02FZdD2Yyv"
      },
      "id": "GS02FZdD2Yyv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f46225e2",
      "metadata": {
        "id": "f46225e2"
      },
      "source": [
        "Python ile hÄ±zlÄ±ca datayÄ± eÄŸitim iÃ§in hazÄ±rla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7baaa94d",
      "metadata": {
        "id": "7baaa94d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "\n",
        "# ðŸ“‚ Dataset ana klasÃ¶rleri\n",
        "test_dir = 'test'   # test/angry, test/disgust, test/fear ...\n",
        "train_dir = 'train' # train/angry, train/disgust, train/fear ...\n",
        "\n",
        "# ðŸ“Œ GÃ¶rselleri yÃ¼kleyen fonksiyon (48x48 dataset iÃ§in)\n",
        "def load_images_from_directory(base_dir, label, img_size=(48, 48), limit=300):\n",
        "    images = []\n",
        "    labels = []\n",
        "    count = 0\n",
        "    for file_name in os.listdir(base_dir):\n",
        "        if count >= limit:  # 300'den sonra dur\n",
        "            break\n",
        "        if file_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "            file_path = os.path.join(base_dir, file_name)\n",
        "            # grayscale yaptÄ±k Ã§Ã¼nkÃ¼ kaynak grayscale\n",
        "            img = tf.keras.preprocessing.image.load_img(file_path, target_size=img_size, color_mode=\"grayscale\")\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0  # normalize\n",
        "            images.append(img_array)\n",
        "            labels.append(label)\n",
        "            count += 1\n",
        "    return images, labels\n",
        "\n",
        "# Duygu klasÃ¶rleri ve etiketleri\n",
        "emotion_dirs = {\n",
        "    \"angry\": 0,\n",
        "    \"disgust\": 1,\n",
        "    \"fear\": 2,\n",
        "    \"happy\": 3,\n",
        "    \"neutral\": 4,\n",
        "    \"surprise\": 5,\n",
        "    \"sad\": 6\n",
        "}\n",
        "\n",
        "# --- Train verisi ---\n",
        "train_images, train_labels = [], []\n",
        "for emotion, label in emotion_dirs.items():\n",
        "    img_dir = os.path.join(train_dir, emotion)\n",
        "    images, labels = load_images_from_directory(img_dir, label=label)\n",
        "    train_images.extend(images)\n",
        "    train_labels.extend(labels)\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# --- Test verisi ---\n",
        "test_images, test_labels = [], []\n",
        "for emotion, label in emotion_dirs.items():\n",
        "    img_dir = os.path.join(test_dir, emotion)\n",
        "    images, labels = load_images_from_directory(img_dir, label=label)\n",
        "    test_images.extend(images)\n",
        "    test_labels.extend(labels)\n",
        "\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "\n",
        "X_train, y_train = train_images, train_labels\n",
        "X_test, y_test = test_images, test_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5be808c3",
      "metadata": {
        "id": "5be808c3"
      },
      "outputs": [],
      "source": [
        "print(\"Elindeki veri miktarÄ± ve test train daÄŸlÄ±mÄ±\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "print(\"Train samples:\", len(X_train))\n",
        "print(\"Test samples:\", len(X_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Functions"
      ],
      "metadata": {
        "id": "wsp0pRP21wIP"
      },
      "id": "wsp0pRP21wIP"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
        "\n",
        "def compile_and_train_timed(model, name, epochs=15, batch_size=32):\n",
        "    \"\"\"\n",
        "    Compiles, trains the model, and returns:\n",
        "    model, history, training_time_in_seconds\n",
        "    \"\"\"\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=1\n",
        "    )\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"{name} training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    return model, history, training_time\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_flops(model, batch_size=1):\n",
        "    \"\"\"\n",
        "    Calculate FLOPs for a Keras model.\n",
        "    Returns total float operations (FLOPs).\n",
        "    \"\"\"\n",
        "    # Make sure model is built\n",
        "    if not model.built:\n",
        "        model.build((None, 48, 48, 1))  # adjust input size if needed\n",
        "\n",
        "    # Create concrete function\n",
        "    concrete = tf.function(lambda inputs: model(inputs))\n",
        "    concrete = concrete.get_concrete_function(\n",
        "        tf.TensorSpec([batch_size] + list(model.input_shape[1:]), model.inputs[0].dtype)\n",
        "    )\n",
        "\n",
        "    # Get frozen graph\n",
        "    frozen_func = tf.graph_util.convert_variables_to_constants_v2(concrete)\n",
        "    graph_def = frozen_func.graph.as_graph_def()\n",
        "\n",
        "    # Run profiler\n",
        "    with tf.Graph().as_default() as graph:\n",
        "        tf.graph_util.import_graph_def(graph_def, name=\"\")\n",
        "        run_meta = tf.compat.v1.RunMetadata()\n",
        "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "        flops = tf.compat.v1.profiler.profile(\n",
        "            graph=graph, run_meta=run_meta, cmd=\"op\", options=opts\n",
        "        )\n",
        "    return flops.total_float_ops\n"
      ],
      "metadata": {
        "id": "SHl02fsY1zJe"
      },
      "id": "SHl02fsY1zJe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN\n"
      ],
      "metadata": {
        "id": "dj6P-ScV110M"
      },
      "id": "dj6P-ScV110M"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn(input_shape=(48,48,1), num_classes=7):\n",
        "    return models.Sequential([\n",
        "        layers.Conv2D(32,3,activation='relu',input_shape=input_shape),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64,3,activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128,3,activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128,activation='relu'),\n",
        "        layers.Dense(num_classes,activation='softmax')\n",
        "    ])\n",
        "\n",
        "cnn_model = build_cnn()\n",
        "\n",
        "# Summary\n",
        "cnn_model.summary()\n",
        "tf.keras.utils.plot_model(cnn_model, to_file=\"model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Plot model architecture\n",
        "tf.keras.utils.plot_model(\n",
        "    cnn_model, to_file=\"cnn_model.png\",\n",
        "    show_shapes=True, show_layer_names=True, dpi=80\n",
        ")\n",
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "visualkeras.layered_view(cnn_model, legend=True, to_file=\"cnn_visual.png\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3LPiMMLw11kw"
      },
      "id": "3LPiMMLw11kw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(cnn_model, to_file=\"model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n"
      ],
      "metadata": {
        "id": "HWK7T0gAyhv6"
      },
      "id": "HWK7T0gAyhv6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "cnn, hist_cnn, time_cnn = compile_and_train_timed(cnn_model, \"CNN\")"
      ],
      "metadata": {
        "id": "YCbdRvSb3lBl"
      },
      "id": "YCbdRvSb3lBl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet"
      ],
      "metadata": {
        "id": "moaLHumA3kyK"
      },
      "id": "moaLHumA3kyK"
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, filters, stride=1):\n",
        "    shortcut = x\n",
        "    x = layers.Conv2D(filters,3,padding='same',strides=stride)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(filters,3,padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    if stride!=1 or shortcut.shape[-1]!=filters:\n",
        "        shortcut = layers.Conv2D(filters,1,strides=stride,padding='same')(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "    x = layers.add([x,shortcut])\n",
        "    return layers.ReLU()(x)\n",
        "\n",
        "def build_resnet(input_shape=(48,48,1), num_classes=7):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32,3,padding='same',activation='relu')(inp)\n",
        "    x = residual_block(x,32)\n",
        "    x = residual_block(x,64,stride=2)\n",
        "    x = residual_block(x,128,stride=2)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    out = layers.Dense(num_classes,activation='softmax')(x)\n",
        "    return models.Model(inp,out)\n",
        "\n",
        "resnet_model = build_resnet()\n",
        "\n",
        "# Summary\n",
        "resnet_model.summary()\n",
        "\n",
        "# Keras plot\n",
        "tf.keras.utils.plot_model(resnet_model, to_file=\"resnet_model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Visualkeras layered view\n",
        "visualkeras.layered_view(resnet_model, legend=True, to_file=\"resnet_visual.png\")\n"
      ],
      "metadata": {
        "id": "dM0Kx5V536Ah"
      },
      "id": "dM0Kx5V536Ah",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(resnet_model, to_file=\"model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n"
      ],
      "metadata": {
        "id": "stgodmdfylGx"
      },
      "id": "stgodmdfylGx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "resnet, hist_resnet, time_resnet = compile_and_train_timed(resnet_model, \"ResNet\")\n"
      ],
      "metadata": {
        "id": "W1orCBHq37vm"
      },
      "id": "W1orCBHq37vm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNet"
      ],
      "metadata": {
        "id": "0VMwaelP4iJN"
      },
      "id": "0VMwaelP4iJN"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "def build_densenet(input_shape=(48,48,1), num_classes=7):\n",
        "    base = DenseNet121(weights=None, include_top=False, input_shape=input_shape)\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return models.Model(base.input, out)\n",
        "\n",
        "densenet_model = build_densenet()\n",
        "\n",
        "# Summary\n",
        "densenet_model.summary()\n",
        "\n",
        "# Keras plot\n",
        "tf.keras.utils.plot_model(densenet_model, to_file=\"densenet_model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Visualkeras layered view\n",
        "visualkeras.layered_view(densenet_model, legend=True, to_file=\"densenet_visual.png\")\n"
      ],
      "metadata": {
        "id": "HIhYoGS44kxe"
      },
      "id": "HIhYoGS44kxe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(densenet_model, to_file=\"model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n"
      ],
      "metadata": {
        "id": "NtfwcU_Hyr8w"
      },
      "id": "NtfwcU_Hyr8w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "densenet, hist_densenet, time_densenet = compile_and_train_timed(densenet_model, \"DenseNet\")\n"
      ],
      "metadata": {
        "id": "IMO329Ca4o7p"
      },
      "id": "IMO329Ca4o7p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EfficientNet"
      ],
      "metadata": {
        "id": "jiuSHPnQ4snV"
      },
      "id": "jiuSHPnQ4snV"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "def build_efficientnet(input_shape=(48,48,1), num_classes=7):\n",
        "    base = EfficientNetB0(weights=None, include_top=False, input_shape=input_shape)\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return models.Model(base.input, out)\n",
        "\n",
        "efficientnet_model = build_efficientnet()\n",
        "\n",
        "# Summary\n",
        "efficientnet_model.summary()\n",
        "\n",
        "# Keras plot\n",
        "tf.keras.utils.plot_model(efficientnet_model, to_file=\"efficientnet_model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Visualkeras layered view\n",
        "visualkeras.layered_view(efficientnet_model, legend=True, to_file=\"efficientnet_visual.png\")\n"
      ],
      "metadata": {
        "id": "Was9Yy5Q4wqp"
      },
      "id": "Was9Yy5Q4wqp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(efficientnet_model, to_file=\"model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n"
      ],
      "metadata": {
        "id": "xE9LXqzJywRp"
      },
      "id": "xE9LXqzJywRp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "efficientnet, hist_eff, time_eff = compile_and_train_timed(efficientnet_model, \"EfficientNet\")\n"
      ],
      "metadata": {
        "id": "mzsduLzv41je"
      },
      "id": "mzsduLzv41je",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN + SE (Attention)"
      ],
      "metadata": {
        "id": "HoLDV4CX47rq"
      },
      "id": "HoLDV4CX47rq"
    },
    {
      "cell_type": "code",
      "source": [
        "def se_block(x, ratio=8):\n",
        "    f = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(f//ratio,activation='relu')(se)\n",
        "    se = layers.Dense(f,activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1,1,f))(se)\n",
        "    return layers.multiply([x,se])\n",
        "\n",
        "def build_cnn_se(input_shape=(48,48,1), num_classes=7):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32,3,activation='relu',padding='same')(inp)\n",
        "    x = se_block(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64,3,activation='relu',padding='same')(x)\n",
        "    x = se_block(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    out = layers.Dense(num_classes,activation='softmax')(x)\n",
        "    return models.Model(inp,out)\n",
        "\n",
        "cnn_se_model = build_cnn_se()\n",
        "\n",
        "# Summary\n",
        "cnn_se_model.summary()\n",
        "\n",
        "# Keras plot\n",
        "tf.keras.utils.plot_model(cnn_se_model, to_file=\"cnn_se_model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Visualkeras layered view\n",
        "visualkeras.layered_view(cnn_se_model, legend=True, to_file=\"cnn_se_visual.png\")\n"
      ],
      "metadata": {
        "id": "Gyyr002l46Yb"
      },
      "id": "Gyyr002l46Yb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(cnn_se_model, to_file=\"model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n"
      ],
      "metadata": {
        "id": "FN6gw-iSyztB"
      },
      "id": "FN6gw-iSyztB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "cnn_se, hist_se, time_se = compile_and_train_timed(cnn_se_model, \"CNN-SE\")\n"
      ],
      "metadata": {
        "id": "staCWiU05Ce1"
      },
      "id": "staCWiU05Ce1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vision Transformer"
      ],
      "metadata": {
        "id": "hLqfy_dP5Gl7"
      },
      "id": "hLqfy_dP5Gl7"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vit(input_shape=(48,48,1), num_classes=7,\n",
        "              patch_size=6, num_heads=4, proj_dim=64, layers_num=2):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(3,1)(inp)  # convert grayscale -> 3 channels\n",
        "    patches = layers.Conv2D(proj_dim, patch_size, strides=patch_size)(x)\n",
        "    patches = layers.Reshape((-1,proj_dim))(patches)\n",
        "    positions = tf.range(start=0, limit=patches.shape[1], delta=1)\n",
        "    pos_emb = layers.Embedding(input_dim=patches.shape[1], output_dim=proj_dim)(positions)\n",
        "    x = patches + pos_emb\n",
        "    for _ in range(layers_num):\n",
        "        attn = layers.MultiHeadAttention(num_heads=num_heads,key_dim=proj_dim)(x,x)\n",
        "        x = layers.Add()([x,attn])\n",
        "        x = layers.LayerNormalization()(x)\n",
        "        mlp = models.Sequential([layers.Dense(proj_dim*2,activation='relu'),\n",
        "                                 layers.Dense(proj_dim)])\n",
        "        x = layers.Add()([x,mlp(x)])\n",
        "        x = layers.LayerNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    out = layers.Dense(num_classes,activation='softmax')(x)\n",
        "    return models.Model(inp,out)\n",
        "\n",
        "vit_model = build_vit()\n",
        "\n",
        "# Summary\n",
        "vit_model.summary()\n",
        "\n",
        "# Keras plot\n",
        "tf.keras.utils.plot_model(vit_model, to_file=\"vit_model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n",
        "\n",
        "# Visualkeras layered view\n",
        "visualkeras.layered_view(vit_model, legend=True, to_file=\"vit_visual.png\")\n"
      ],
      "metadata": {
        "id": "mQTrK9wo5GFr"
      },
      "id": "mQTrK9wo5GFr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(vit_model, to_file=\"model.png\", show_shapes=True, show_layer_names=True, dpi=80)\n"
      ],
      "metadata": {
        "id": "eaJUFIW4y8iZ"
      },
      "id": "eaJUFIW4y8iZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "vit, hist_vit, time_vit = compile_and_train_timed(vit_model, \"ViT\")"
      ],
      "metadata": {
        "id": "z8n_PPpX5MHC"
      },
      "id": "z8n_PPpX5MHC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare Models"
      ],
      "metadata": {
        "id": "LBV4U1VD5dqE"
      },
      "id": "LBV4U1VD5dqE"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "histories = {\n",
        "    \"CNN\": hist_cnn,\n",
        "    \"ResNet\": hist_resnet,\n",
        "    \"DenseNet\": hist_densenet,\n",
        "    \"EfficientNet\": hist_eff,\n",
        "    \"CNN+SE\": hist_se,\n",
        "    \"ViT\": hist_vit\n",
        "}\n",
        "\n",
        "models_dict = {\n",
        "    \"CNN\": cnn,\n",
        "    \"ResNet\": resnet,\n",
        "    \"DenseNet\": densenet,\n",
        "    \"EfficientNet\": efficientnet,\n",
        "    \"CNN+SE\": cnn_se,\n",
        "    \"ViT\": vit\n",
        "}\n",
        "\n",
        "training_times = {\n",
        "    \"CNN\": time_cnn,\n",
        "    \"ResNet\": time_resnet,\n",
        "    \"DenseNet\": time_densenet,\n",
        "    \"EfficientNet\": time_eff,\n",
        "    \"CNN+SE\": time_se,\n",
        "    \"ViT\": time_vit\n",
        "}\n",
        "\n",
        "# Plot validation accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "for name,h in histories.items():\n",
        "    plt.plot(h.history['val_accuracy'], label=name)\n",
        "plt.legend(); plt.xlabel(\"Epochs\"); plt.ylabel(\"Val Accuracy\")\n",
        "plt.title(\"FER Model Zoo Comparison\")\n",
        "plt.show()\n",
        "\n",
        "# Print parameters, FLOPs, and training time\n",
        "for name, m in models_dict.items():\n",
        "  if not m.built:\n",
        "        m.build((None, 48, 48, 1))\n",
        "  print(f\"{name}: Params={m.count_params():,}, FLOPsâ‰ˆ{get_flops(m):,}, Training time={training_times[name]:.1f}s\")\n"
      ],
      "metadata": {
        "id": "71Acgt_G5hg2"
      },
      "id": "71Acgt_G5hg2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Predictions"
      ],
      "metadata": {
        "id": "EyfnjFbT52sH"
      },
      "id": "EyfnjFbT52sH"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_random_predictions(models_dict, X, y, num_images=5):\n",
        "    idxs = random.sample(range(len(X)), num_images)\n",
        "    fig, axes = plt.subplots(num_images, len(models_dict)+1, figsize=(15,3*num_images))\n",
        "    for i, idx in enumerate(idxs):\n",
        "        img, true_label = X[idx], emotion_labels[y[idx]]\n",
        "        axes[i,0].imshow(img.squeeze(), cmap='gray')\n",
        "        axes[i,0].set_title(f\"True: {true_label}\")\n",
        "        axes[i,0].axis(\"off\")\n",
        "        for j,(name,model) in enumerate(models_dict.items(),start=1):\n",
        "            pred = model.predict(img[np.newaxis,...], verbose=0)\n",
        "            pred_label = emotion_labels[np.argmax(pred)]\n",
        "            axes[i,j].imshow(img.squeeze(), cmap='gray')\n",
        "            axes[i,j].set_title(f\"{name}: {pred_label}\")\n",
        "            axes[i,j].axis(\"off\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "show_random_predictions(models_dict, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "uEMZh8kQ549s"
      },
      "id": "uEMZh8kQ549s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test on your Image"
      ],
      "metadata": {
        "id": "k0kuk__l57eu"
      },
      "id": "k0kuk__l57eu"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_custom(models_dict, filepath, target_size=(48,48)):\n",
        "    img = image.load_img(filepath, target_size=target_size, color_mode=\"grayscale\")\n",
        "    arr = image.img_to_array(img)/255.0\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    plt.imshow(arr[0].squeeze(), cmap='gray')\n",
        "    plt.axis(\"off\"); plt.title(\"Custom image\"); plt.show()\n",
        "    for name, model in models_dict.items():\n",
        "        pred = model.predict(arr, verbose=0)\n",
        "        print(f\"{name}: {emotion_labels[np.argmax(pred)]}\")\n",
        "\n",
        "# Example:\n",
        "# predict_custom(models_dict, \"my_face.png\")\n"
      ],
      "metadata": {
        "id": "szO4eMp05-gc"
      },
      "id": "szO4eMp05-gc",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}