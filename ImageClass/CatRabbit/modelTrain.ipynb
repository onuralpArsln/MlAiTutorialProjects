{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/ImageClass/CatRabbit/modelTrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-14cIIXG1NUt"
      },
      "source": [
        "# Pytorch ile Kendi Datasetinden Eğitim\n",
        "\n",
        "\n",
        "Bir çok tutorialda torchvision dataset içinden hızlıca bir dataset çekmek tercih edilir çünkü çok kolayca düzgün bir dataset oluşturmuş olursun.\n",
        "\n",
        "Biz bugün kendi elimizdeki bir data seti kullanarak bu işlemleri yapacağız.\n",
        "\n",
        "Bunun için bir bulk downloader uzantısı ile googledan bir çok resmi hızlıca kayıt edebilir ya da elimizdeki hazır bir seti kullanabiliriz. Araştırmalar sırasında video çekip bu videodan bir python scripti ile ekran görüntüleri almak gibi teknikler ile de veri setleri hızlıca oluşturulabilir\n",
        "\n",
        "ancak data bir miktar düzenlemeye ihtiyaç duyabilir.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0wc_m181NUu"
      },
      "source": [
        "# Database yapısı\n",
        "\n",
        "\n",
        "Oldukça basit bir yapıyı takip edeceğiz\n",
        "                                      \n",
        "data/                                           \n",
        "├─ cat/             \n",
        "│  ├─ image001.jpg             \n",
        "│  ├─ image002.jpg             \n",
        "│  ├─ ....             \n",
        "├─ rabbit/             \n",
        "│  ├─ image001.jpg             \n",
        "│  ├─ image002.jpg             \n",
        "│  ├─ ....             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3fQPwwG1NUv"
      },
      "source": [
        "Bu dosya hem zipli hem de sıkıştırılmamış olarak repoda mevcut. Zipli hali colabda çalışırken wget ile kolayca indirmen için"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9TrlErX1NUv"
      },
      "source": [
        "Colabde isen kolayca indir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-e1RhwPL1NUv",
        "outputId": "03ccea0f-3ec2-4c48-8fc0-18a0d264df4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-17 13:15:25--  https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/ImageClass/CatRabbit/data.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/onuralpArsln/MlAiTutorialProjects/main/ImageClass/CatRabbit/data.zip [following]\n",
            "--2024-07-17 13:15:26--  https://raw.githubusercontent.com/onuralpArsln/MlAiTutorialProjects/main/ImageClass/CatRabbit/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 74171382 (71M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  70.73M   125MB/s    in 0.6s    \n",
            "\n",
            "2024-07-17 13:15:27 (125 MB/s) - ‘data.zip’ saved [74171382/74171382]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/ImageClass/CatRabbit/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "geJT3k_G1NUv"
      },
      "outputs": [],
      "source": [
        "!unzip -q data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHJQJzAa1NUw"
      },
      "source": [
        "# Define Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i4zxds-1NUw"
      },
      "source": [
        "Transfromların olay resimlere rastgele değişimler uygulamaktır.  \n",
        "\n",
        "Bu hem elimizdeki data miktarını arttırmak için güzel bir metot hem de farklı koşullar altında da tanıma yapabilmek için önemli.\n",
        "\n",
        "Örneğin rastgele döndürmeler eklemek sayesinde eğer kedi baş aşağı durursa da onu tanıyacağız.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-AEkKLgN1NUw"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b85lyUt51NUw"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py5Fi-UL1NUw"
      },
      "source": [
        "# Data setimizi aktarmak\n",
        "\n",
        "Bu noktada bizim data setimiz düzenli olduğu için bir metot kullanacağız ancak düzensiz bir data setin var ise nasıl çalışman gerektiğinin örneğide olacak\n",
        "\n",
        "\n",
        "Ayrıca bizim data setimizde iki sınıf içinde yakın miktarda görsel var. Bu iyi bir dataset için önemli bir yapıdır."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "QipG5URR1sfO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torchvision.datasets.ImageFolder(root='data', transform=transform)"
      ],
      "metadata": {
        "id": "Y4dXuXZz1uGb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset\n",
        "\n",
        "Eğer dataset dosya yapın bizim örnekteki gibi düzenli değil ise  aşağıdaki methodu uygulayacaksın. Ama düzenli bir datasetine sahip olmak her zaman daha iyidir.\n"
      ],
      "metadata": {
        "id": "jHU2pF_L2J7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data\n",
        "\n",
        "\n",
        "Amacımız test, validation  ve train oluşturmak.\n",
        "\n",
        "\n",
        "validation -> eğitim sırasında parametre optimizasyonu için kullanılan veri kısmı\n",
        "\n",
        "test-> model eğitildikten sonra performans ölçümü için kullanılır."
      ],
      "metadata": {
        "id": "WqXzZTEH2kIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splits = [0.8, 0.1, 0.1]"
      ],
      "metadata": {
        "id": "rJe9yIGn2oWW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_sizes = []\n",
        "for sp in splits[:-1]:\n",
        "    split_sizes.append(int(sp * len(dataset)))\n",
        "split_sizes.append(len(dataset) - sum(split_sizes))"
      ],
      "metadata": {
        "id": "aE4f8NqT3iDS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils\n",
        "train_set, test_set, val_set = torch.utils.data.random_split(dataset, split_sizes)"
      ],
      "metadata": {
        "id": "MKcpD1mO2_B9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, test_set, val_set = torch.utils.data.random_split(dataset, split_sizes)"
      ],
      "metadata": {
        "id": "0eW1ruu_3o3O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_set.transform = test_set.transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128))\n",
        "])"
      ],
      "metadata": {
        "id": "U7ANJfsp3qA6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "dcbuVlLO3rq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "AeRNBRWu3uBc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {\n",
        "    \"train\": DataLoader(train_set, batch_size=16, shuffle=True),\n",
        "    \"test\": DataLoader(test_set, batch_size=16, shuffle=False),\n",
        "    \"val\": DataLoader(val_set, batch_size=16, shuffle=False)\n",
        "}"
      ],
      "metadata": {
        "id": "oJQNiAMg3vBJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Classifier"
      ],
      "metadata": {
        "id": "va_eWoTW4As2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(128, 256)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(256, 3)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "WFmXiRgA4FVs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(128, 256)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(256, 1)\n",
        "        self.softmax = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0COLmObi4IZ5"
      },
      "execution_count": 26,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}