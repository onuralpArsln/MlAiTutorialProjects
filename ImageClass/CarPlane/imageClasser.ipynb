{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/ImageClass/CarPlane/imageClasser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prep\n",
        "\n",
        "Eğer colab ile açtıysan mevcut colab workspaceine data kalsöürnü çekmen lazım neyseki bu çok kolay sadece ağaıdaki komutu kullan"
      ],
      "metadata": {
        "id": "6gPIdEQQlw0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o data.zip https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/ImageClass/CarPlane/data.zip"
      ],
      "metadata": {
        "id": "xXtX-4_unh_3",
        "outputId": "8e093e23-4e88-4b05-831d-95ffa6fc4dbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  256k    0  256k    0     0  1420k      0 --:--:-- --:--:-- --:--:-- 1425k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "id": "-ZBDXh0In4Ps",
        "outputId": "d7e5d3d0-4257-4b70-9374-ad1eaef321ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of data.zip or\n",
            "        data.zip.zip, and cannot find data.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bMC2-Wbln32"
      },
      "source": [
        "# Classification Model With Keras\n",
        "\n",
        "\n",
        "Bu çalışmada Keras kullanarak bir sınıflandırma yapacağız.\n",
        "\n",
        "Data klasörü içine bakarak kullanacağımız görsellere bakabilirsin.\n",
        "\n",
        "Toplamda 500 adet görsel mevcuttur.\n",
        "\n",
        "\n",
        "200 uçak ve 200 araba görseli modeli eğitmek için 50 uçak ve 50 araba görseli modeli test etmek için kullanılacak.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVRy6kHYln37"
      },
      "outputs": [],
      "source": [
        "# keras versiyonuna göre yorum bu altaki iki importtan birini yapman gerekebilir\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# keras versiyonuna göre yorum bu yukardaki iki importtan birini yapman\n",
        "# yorum satırını değiştirmeyi dene hata alırsan\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "img_width, img_height = 224, 224\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nRoNAGcln39"
      },
      "source": [
        "görüntüler 224 pixele 224 pixel. Sınıflandırma için süper hd bir görüntüye gerek yok. Görüntülerde hızlıca çalışmak sınıflandırma için daha verimli olacak.\n",
        "\n",
        "değişkenlerimize bilgileri atıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaQIUgmUln3-"
      },
      "outputs": [],
      "source": [
        "train_data_dir = 'data/train'\n",
        "validation_data_dir = 'data/test'\n",
        "nb_train_samples =400\n",
        "nb_validation_samples = 100\n",
        "epochs = 10\n",
        "batch_size = 16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "610Z9w_8ln3-"
      },
      "source": [
        "Epoch ve Batch_size önemli kavramlar  \n",
        "\n",
        "Epoch basitçe veri seti üzerinde kça iterasyon yapılacağını ifade eder\n",
        "\n",
        "Batch size ise bir seferde incelenecek örnek sayısını ifade eder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRnq60Isln3_"
      },
      "outputs": [],
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "\tinput_shape = (3, img_width, img_height)\n",
        "else:\n",
        "\tinput_shape = (img_width, img_height, 3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p3NgnZFln3_"
      },
      "source": [
        "Burada amaç veri formatının düzgün aktarılmasından emin olmak. Channels Rgb kanalları, eğer rgb kanalları ilk yazılır ise önce kanal sonra boyut verilir. Aksi halde önce boyut sonra kanal ifade ediliyor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLogoyXsln3_",
        "outputId": "d5c80384-b6f7-47e5-90cd-760af15beb2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/onuralp/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(\n",
            "2024-07-16 15:30:27.249532: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-07-16 15:30:27.251303: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDmrdY0Yln4A"
      },
      "source": [
        "Burada aslında ağ mimarisini yazdık. daha ileri seviye çalışmalar için mevcut başarılı mimariler kullanmak güzeldir ama ne olduğu görmek için önemli bi adım    \n",
        "\n",
        "\n",
        "\n",
        "Conv2D , görüntüyü birden fazla görüntüye evriştiren katmandır.\n",
        "\n",
        "\n",
        "Aktivasyon , aktivasyon fonksiyonudur.\n",
        "MaxPooling2D, verilen boyut matrisindeki değeri maksimuma çıkarmak için kullanılır ve aynısı sonraki 2 katman için kullanılır. daha sonra Düzleştir , evriştirildikten sonra elde edilen görüntünün boyutlarını düzleştirmek için kullanılır.\n",
        "Yoğun, bunu tamamen bağlantılı bir model haline getirmek için kullanılır ve gizli katmandır.\n",
        "Bırakma, veri kümesine aşırı sığmayı önlemek için kullanılır.\n",
        "Yoğun, çıktı katmanının görüntünün hangi kategoriye ait olduğuna karar veren yalnızca bir nöron içermesidir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb9a3CEDln4A"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "\t\t\toptimizer='rmsprop',\n",
        "\t\t\tmetrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHzEdpRdln4B"
      },
      "source": [
        "Burada kayıp, optimize ediciler ve metriklerin kullanımını içeren derleme işlevi kullanılmıştır. Burada kullanılan kayıp fonksiyonu Binary_crossentropy, kullanılan optimizer ise rmsprop'tur ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZXc1j2Bln4B",
        "outputId": "c0bca61d-3a08-48eb-cc80-2a4bfc2ae7d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pillow\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-10.4.0\n"
          ]
        }
      ],
      "source": [
        "# eğer aşağıda pil ile ilgili hata alaırsan bunu kullan\n",
        "!pip3 install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svcKTMHGln4C",
        "outputId": "0e01851d-424b-4c4a-cc78-cb10ab9a19f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/onuralp/.local/lib/python3.10/site-packages/PIL/Image.py\n",
            "/home/onuralp/.local/lib/python3.10/site-packages/PIL/Image.py\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from PIL import Image\n",
        "sys.modules['Image'] = Image\n",
        "from PIL import Image\n",
        "print(Image.__file__)\n",
        "import Image\n",
        "print(Image.__file__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixV_P4Mqln4C",
        "outputId": "9dca776b-a344-4b2d-868f-666eff95d418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400 images belonging to 2 classes.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 21\u001b[0m\n\u001b[1;32m      9\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m     10\u001b[0m \ttrain_data_dir,\n\u001b[1;32m     11\u001b[0m \ttarget_size\u001b[38;5;241m=\u001b[39m(img_width, img_height),\n\u001b[1;32m     12\u001b[0m \tbatch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     13\u001b[0m \tclass_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m     16\u001b[0m \tvalidation_data_dir,\n\u001b[1;32m     17\u001b[0m \ttarget_size\u001b[38;5;241m=\u001b[39m(img_width, img_height),\n\u001b[1;32m     18\u001b[0m \tbatch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     19\u001b[0m \tclass_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m\t\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_train_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_validation_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/image_utils.py:227\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03mUsage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    A PIL Image instance.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import PIL.Image. The use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, io\u001b[38;5;241m.\u001b[39mBytesIO):\n\u001b[1;32m    231\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(path)\n",
            "\u001b[0;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "\trescale=1. / 255,\n",
        "\tshear_range=0.2,\n",
        "\tzoom_range=0.2,\n",
        "\thorizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\ttrain_data_dir,\n",
        "\ttarget_size=(img_width, img_height),\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "\tvalidation_data_dir,\n",
        "\ttarget_size=(img_width, img_height),\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "model.fit(\n",
        "\ttrain_generator,\n",
        "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
        "\tepochs=epochs,\n",
        "\tvalidation_data=validation_generator,\n",
        "\tvalidation_steps=nb_validation_samples // batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1iu-9KBln4C"
      },
      "source": [
        "Şimdi dataGenerator'ın kısmı devreye giriyor. Hangisinde kullandık:\n",
        "\n",
        "Görüntüyü yeniden ölçeklendiren, belirli bir aralıkta kesme uygulayan, görüntüyü yakınlaştıran ve görüntüyle yatay çevirme yapan ImageDataGenerator . Bu ImageDataGenerator görüntünün tüm olası yönelimlerini içerir.\n",
        "train_datagen.flow_from_directory, train_dataset dizininden veri hazırlamak için kullanılan işlevdir Target_size, görüntünün hedef boyutunu belirtir.\n",
        "test_datagen.flow_from_directory , model için test verilerini hazırlamak için kullanılır ve hepsi yukarıdakine benzer.\n",
        "fit_generator, verileri yukarıda yapılan modele sığdırmak için kullanılır; kullanılan diğer faktörler,step_per_epochs'tur ve bize modelin eğitim verileri için kaç kez yürütüleceğini bildirir.\n",
        "Epochs bize modelin ileri ve geri geçişte kaç kez eğitileceğini söyler.\n",
        "validation_data, doğrulama/test verilerini modele beslemek için kullanılır.\n",
        "validation_steps doğrulama/test örneklerinin sayısını belirtir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpIf5m64ln4D",
        "outputId": "d0b1b66a-5766-4c44-f2c2-fa6c2e8d2051"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The filename must end in `.weights.h5`. Received: filepath=model_saved.h5",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_saved.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/models/model.py:319\u001b[0m, in \u001b[0;36mModel.save_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Saves all layer weights to a `.weights.h5` file.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m        via an interactive prompt.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filename must end in `.weights.h5`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     exists \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filepath)\n",
            "\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=model_saved.h5"
          ]
        }
      ],
      "source": [
        "model.save_weights('model_saved.weights.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOoyQSnsln4D"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('model_saved.weights.h5')\n",
        "\n",
        "image = load_img('v_data/test/planes/5.jpg', target_size=(224, 224))\n",
        "img = np.array(image)\n",
        "img = img / 255.0\n",
        "img = img.reshape(1,224,224,3)\n",
        "label = model.predict(img)\n",
        "print(\"Predicted Class (0 - Cars , 1- Planes): \", label[0][0])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}