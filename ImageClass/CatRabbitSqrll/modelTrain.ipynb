{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/ImageClass/CatRabbitSqrll/modelTrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-14cIIXG1NUt"
      },
      "source": [
        "# Pytorch ile Kendi Datasetinden Eğitim\n",
        "\n",
        "\n",
        "Bir çok tutorialda torchvision dataset içinden hızlıca bir dataset çekmek tercih edilir çünkü çok kolayca düzgün bir dataset oluşturmuş olursun.\n",
        "\n",
        "Biz bugün kendi elimizdeki bir data seti kullanarak bu işlemleri yapacağız.\n",
        "\n",
        "Bunun için bir bulk downloader uzantısı ile googledan bir çok resmi hızlıca kayıt edebilir ya da elimizdeki hazır bir seti kullanabiliriz. Araştırmalar sırasında video çekip bu videodan bir python scripti ile ekran görüntüleri almak gibi teknikler ile de veri setleri hızlıca oluşturulabilir\n",
        "\n",
        "ancak data bir miktar düzenlemeye ihtiyaç duyabilir.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0wc_m181NUu"
      },
      "source": [
        "# Database yapısı\n",
        "\n",
        "\n",
        "Oldukça basit bir yapıyı takip edeceğiz\n",
        "                                      \n",
        "data/                                           \n",
        "├─ cat/             \n",
        "│  ├─ image001.jpg             \n",
        "│  ├─ image002.jpg             \n",
        "│  ├─ ....             \n",
        "├─ rabbit/             \n",
        "│  ├─ image001.jpg             \n",
        "│  ├─ image002.jpg             \n",
        "│  ├─ ....      \n",
        "├─ squirrel/             \n",
        "│  ├─ image001.jpg             \n",
        "│  ├─ image002.jpg             \n",
        "│  ├─ ....         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3fQPwwG1NUv"
      },
      "source": [
        "Bu dosya hem zipli hem de sıkıştırılmamış olarak repoda mevcut. Zipli hali colabda çalışırken wget ile kolayca indirmen için"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9TrlErX1NUv"
      },
      "source": [
        "Colabde isen kolayca indir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e1RhwPL1NUv",
        "outputId": "08cc4319-db8f-4d55-d015-03cbf35bd324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-18 09:30:45--  https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/ImageClass/CatRabbitSqrll/data.zip\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/onuralpArsln/MlAiTutorialProjects/main/ImageClass/CatRabbitSqrll/data.zip [following]\n",
            "--2024-07-18 09:30:45--  https://raw.githubusercontent.com/onuralpArsln/MlAiTutorialProjects/main/ImageClass/CatRabbitSqrll/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76061926 (73M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  72.54M  85.2MB/s    in 0.9s    \n",
            "\n",
            "2024-07-18 09:30:50 (85.2 MB/s) - ‘data.zip’ saved [76061926/76061926]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/ImageClass/CatRabbitSqrll/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "geJT3k_G1NUv"
      },
      "outputs": [],
      "source": [
        "!unzip -q data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHJQJzAa1NUw"
      },
      "source": [
        "# Define Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i4zxds-1NUw"
      },
      "source": [
        "Transfromların olay resimlere rastgele değişimler uygulamaktır.  \n",
        "\n",
        "Bu hem elimizdeki data miktarını arttırmak için güzel bir metot hem de farklı koşullar altında da tanıma yapabilmek için önemli.\n",
        "\n",
        "Örneğin rastgele döndürmeler eklemek sayesinde eğer kedi baş aşağı durursa da onu tanıyacağız.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-AEkKLgN1NUw"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "b85lyUt51NUw"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu transformlar  oldukça önemli. Oncelikle resim boytlarımızı sabit bir şekilde almak sistemin çalışması için önemli. Girdilerimiz sabit bir boyuta aldık.\n",
        "resimleri tensore çevirerek sistem tarafından anlaşılır bir hale getirdik. Rastgele dönmeler eklemek ise farklı koşullar altında tanımayı kolaylaştırır."
      ],
      "metadata": {
        "id": "FJcezpJgdbxM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py5Fi-UL1NUw"
      },
      "source": [
        "# Data setimizi aktarmak\n",
        "\n",
        "Bu noktada bizim data setimiz düzenli olduğu için bir metot kullanacağız ancak düzensiz bir data setin var ise nasıl çalışman gerektiğinin örneğide olacak\n",
        "\n",
        "\n",
        "Ayrıca bizim data setimizde iki sınıf içinde yakın miktarda görsel var. Bu iyi bir dataset için önemli bir yapıdır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QipG5URR1sfO"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Y4dXuXZz1uGb"
      },
      "outputs": [],
      "source": [
        "dataset = torchvision.datasets.ImageFolder(root='data', transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHU2pF_L2J7h"
      },
      "source": [
        "# Custom Dataset\n",
        "\n",
        "Eğer dataset dosya yapın bizim örnekteki gibi düzenli değil ise  aşağıdaki methodu uygulayacaksın. Ama düzenli bir datasetine sahip olmak her zaman daha iyidir.\n",
        "\n",
        "__init__(), __len__(), ve __get_item__() methodlarını tanımlamak zorundasın sistemin çalışması için"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gOnGAbUL4Vl0"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "#glob ve os sistem dizin kontrolü için\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    # transform ve dosya adresi bilgilerini alarak objeyi başlatır.\n",
        "    def __init__(self, root_dir, transform):\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        # tercih edilen dosya uzantılarını buraya yaz bizde sadece png ve jpeg mevcut\n",
        "        for ext in ['png', 'jpg']:\n",
        "            self.image_paths += glob.glob(os.path.join(root_dir, '*', f'*.{ext}'))\n",
        "        # set oluşturmak her dizine sadece bir kere uğramak için\n",
        "        class_set = set()\n",
        "        # mevcut olan her resim adresini ekle\n",
        "        for path in self.image_paths:\n",
        "            class_set.add(os.path.dirname(path))\n",
        "        self.class_lbl = { cls: i for i, cls in enumerate(sorted(list(class_set)))}\n",
        "    #  veri  setinin boyutunu döndürebilmek için bir method\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    # idx indexideki veriyi yükler\n",
        "    def __getitem__(self, idx):\n",
        "        img = read_image(self.image_paths[idx], ImageReadMode.RGB).float()\n",
        "        cls = os.path.basename(os.path.dirname(self.image_paths[idx]))\n",
        "        label = self.class_lbl[cls]\n",
        "        # label bilgisinide paylaşır\n",
        "        return self.transform(img), torch.tensor(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "k3z695gR4YvT"
      },
      "outputs": [],
      "source": [
        "custom_dataset = CustomDataset('data/', transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqXzZTEH2kIV"
      },
      "source": [
        "# Split Data\n",
        "\n",
        "\n",
        "Amacımız test, validation  ve train oluşturmak.\n",
        "\n",
        "train-> eğitim için kullanılcak veri\n",
        "\n",
        "validation -> eğitim sırasında parametre optimizasyonu için kullanılan veri kısmı\n",
        "\n",
        "test-> model eğitildikten sonra performans ölçümü için kullanılır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rJe9yIGn2oWW"
      },
      "outputs": [],
      "source": [
        "splits = [0.8, 0.1, 0.1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aE4f8NqT3iDS"
      },
      "outputs": [],
      "source": [
        "split_sizes = []\n",
        "for sp in splits[:-1]:\n",
        "    split_sizes.append(int(sp * len(dataset)))\n",
        "split_sizes.append(len(dataset) - sum(split_sizes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "MKcpD1mO2_B9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils\n",
        "train_set, test_set, val_set = torch.utils.data.random_split(dataset, split_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0eW1ruu_3o3O"
      },
      "outputs": [],
      "source": [
        "train_set, test_set, val_set = torch.utils.data.random_split(dataset, split_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U7ANJfsp3qA6"
      },
      "outputs": [],
      "source": [
        "val_set.transform = test_set.transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcbuVlLO3rq-"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp_HfAbW6Euy"
      },
      "source": [
        "Dataloader pytorch içinde iterasyona izin veren bir yapıdır. böylece verilerini pytorch içinde kullanılacak bir yapıya çevirirsin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AeRNBRWu3uBc"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "oJQNiAMg3vBJ"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\n",
        "    \"train\": DataLoader(train_set, batch_size=16, shuffle=True),\n",
        "    \"test\": DataLoader(test_set, batch_size=16, shuffle=False),\n",
        "    \"val\": DataLoader(val_set, batch_size=16, shuffle=False)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va_eWoTW4As2"
      },
      "source": [
        "# Define the Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnhWPHRY6UgY"
      },
      "source": [
        "Sınıflandırmayı yapan modele classifier denir.\n",
        "\n",
        "her nöral yapı gibi classifier de katmanlardan oluşur. bu katmanları istersek kendimiz elle belirleyebiliriz. Ancak uzmanların hazırladığı güçlü yapılarda pytorch içinden kolayca ulaşılabilir.  Bu tutorialde amacımız öğrenmek olduğu için nasıl yapılıyor göreceğiz ama bir mühendislik uygulaması sırasında iyi ve hazır bir nöral yapıyı kullanmak iyi fikirdir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aduuQKbE7AXS"
      },
      "source": [
        "## Custom Architecture\n",
        "\n",
        "aşağıda iki farklı yapı var. eğer ikiden çok çıkışın / sınıfın varsa çok sayıda nöron gerekir\n",
        "\n",
        "1 0 0      kedi       \n",
        "0 1 0      tavşan                        \n",
        "0 0 1      sincap                    \n",
        "gibi            \n",
        "\n",
        "ancak eğer iki  çıkış lazımsa            \n",
        "1 kuş             \n",
        "0 tavşan                   \n",
        "\n",
        "yapabilirsin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFmXiRgA4FVs"
      },
      "outputs": [],
      "source": [
        "## Çok sınıflı sınıflandırma için\n",
        "\n",
        "\n",
        "class CustomModel(torch.nn.Module):   ## custom model yapmak için miras alınıyor\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__() ## miras alınan parentin init çalışıyor\n",
        "\n",
        "        # linear ( fully connected) bir giriş 128 boyutlu girdi alıyor ve\n",
        "        #256 boyutunda bir tensor dışarı veriyor\n",
        "        self.linear1 = torch.nn.Linear(128, 256)\n",
        "\n",
        "        # ReLu Rectified Linear Unit aktivasyonu ilk layerdan sonra kullanılıyor\n",
        "        self.activation = torch.nn.ReLU()\n",
        "\n",
        "        # aşağıdaki 3 sayısı 3 sınıf olduğu için 4 olsa 4 yazardık\n",
        "        # iki katman var giriş ve çıkış 128 girdi 3 çıktı\n",
        "        self.linear2 = torch.nn.Linear(256, 3)\n",
        "\n",
        "        # soft max katmanı çıktıyı olasılığa dönüştürür.\n",
        "        # softmax çok sınıflı sınıflandırma için daha uygundur.\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "\n",
        "  # ileri yönde modelde harekti yapıyoruz\n",
        "  # x datasını katmanlardan geçiriyor ve sonucu döndürüyor\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0COLmObi4IZ5"
      },
      "outputs": [],
      "source": [
        "## Binary ikili sınıflandırma içi\n",
        "class CustomModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(128, 256)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        # çıktı tek boyutlu yani bu binary sınıflandırma\n",
        "        self.linear2 = torch.nn.Linear(256, 1)\n",
        "        # sigmoid aktivasyon ikili sınıflandırma için daha uygundur.\n",
        "        self.softmax = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Model Architecture from pytroch\n",
        "\n",
        "Modelleri tasarlamak uzmanlık isteyen bir iştir. İleri seviye çalışmalarda işlerimize özel uygulamalar için bunu yapmak zorunda kalabiliriz. Ancak hali hazırda optimize modelleri kendi amacımza uygun olarak editleyip kullanmakta oldukça makul bir fikir.\n",
        "\n",
        "Model eğitimin en önemli noktalarından biride noron ağırlıklarının hesaplanması.\n",
        "\n",
        "hali hazırda eğitilmiş Resneti alıp üzerinde biraz çalışalım."
      ],
      "metadata": {
        "id": "adNjbsIgQv88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights"
      ],
      "metadata": {
        "id": "K1_1hS4wSl73"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "resnet50 modelini ve resnet50 için eğitim ağırlıklarını aldık."
      ],
      "metadata": {
        "id": "BS5QV-tESqIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zbk9RlgSpVG",
        "outputId": "75c72c26-69dd-4551-d62c-ecd77a077a93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 63.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50 ağırlıkları ile modeli aktive ettik."
      ],
      "metadata": {
        "id": "0NPBvZYzSwLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = torch.nn.Sequential(\n",
        "    torch.nn.Linear(2048, 256),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(256, 3)\n",
        ")"
      ],
      "metadata": {
        "id": "GfCzkvJbTZlN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model.fc full connected demektir.  \n",
        "torch.nn.sequential ise bilginin sırayla tüm ağ katmanlarından geçtiğini anlatır.   \n",
        "\n",
        "torch.nn.Linear(2048, 256)  ilk linear katmanda 2048lik giriş ve 256lık çıkış olacak\n",
        "\n",
        "torch.nn.ReLU(): ReLU aktivasyon fonksiyonu, ardından gelen lineer katmanın çıktısını alır. Bu, non-lineerlik ekler ve modelin daha karmaşık ilişkileri öğrenmesine yardımcı olur.\n",
        "\n",
        "\n",
        "torch.nn.Linear(256, 3): bu ise çıkış katmanı olan ikinci katmanı düzenler. Normalde resnet50, 1000 çıkışa sahiptir ancak biz 3 sınıflık çıktı istiyoruz. eğer 4 sınıf istiyorsan bu sayıyı 4 yapmalısın.\n",
        "\n",
        "\n",
        "Bu kod parçası, resnet50 modelinin sonundaki fully connected katmanları değiştirerek, modelin çıkışını 3 farklı sınıfa (veya sınıf sayısına) uyacak şekilde özelleştiriyor. Bu tür bir yapılandırma genellikle transfer learning veya özel veri kümesine özgü uygulamalar için kullanılır, mevcut ağın özellik çıkarma yeteneklerini koruyarak sadece sınıflandırma kısmını değiştirir."
      ],
      "metadata": {
        "id": "MHnToJLvTdjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHED1POXUZn_",
        "outputId": "35917155-9f72-4f0c-a6ac-07f195764bd5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeli cuda ya da cpu için uyumlu olarak ayarlıyoruz."
      ],
      "metadata": {
        "id": "5G8d5aoMUiPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parametreleri dondurmak\n",
        "\n",
        "Eğitim sırasında belli katman ve ağırlıkları sabit tutmak manasına gelen bir uygulamadır.\n",
        "\n",
        "Bizim şuan yaptığımız gibi bir transfer learnin yapıyorsan yani önceden eğitilmiş bir model ve ağırlıklarını alıp kendi ihtiyacın için düzenliyorsan parametre dondurmak işe yarayabilir.\n",
        "\n",
        "Eğitimi hızlandırır ve eski ağırlıkları korumak overfitting reiskini azaltır.\n",
        "\n",
        "Biz eski parametreleri dondururken yeni gelenleri eğitmek istiyoruz.\n"
      ],
      "metadata": {
        "id": "lNgSn53OV5y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# önceden eğitilmiş networke ait parametreleri dondur\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# yeni eklenen ve değişenleri ise eğit.\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "metadata": {
        "id": "BG7fLVVVWpRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "requires_grad  eğer doğru ise gradient bu tensor için hesaplanır değilse hesaplanmaz"
      ],
      "metadata": {
        "id": "rDWZ4L03Xlh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Loss Function and the Optimizer\n",
        "\n",
        "Loss Function -> modelin tahmini ile gerçek sonucun birbirinden uzaklığınız ifade eder.\n",
        "\n",
        "Optimizer -> Loss foksyionunu en azaa indigirmek için yapılan çalışmadır. İki örnek olarak ;\n",
        "\n",
        "Gradient Descent -> loss fonksiyonunun gradientini (eğimin yönünü) kullanarak parametreleri günceller. Loss fonksiyonunu büyük 3 boyutlu  bir grafik olarak düşün.\n",
        "\n",
        "Adam (Adaptive Moment Estimation) ->  adaptif öğrenme oranları ve momentum kullanarak gradient descent'in daha hızlı çalışmasını sağlar."
      ],
      "metadata": {
        "id": "tdYpqLYPXu4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "r8gPALd8Zm7U"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "oE11ktRfZ1pR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.parameters() model ağırlıklarını, lr ise learning ratei optimizera aktarır.\n",
        "\n",
        "learning rate -> parametrelerin güncellenme hızını belirler. küçük değerler yavaş yavaş ggüncellenmeye sebp olur. Bu yerel minimumlara takılma riskini oluşturur ve süreyi uzatabilir.\n",
        "yüksek rateler ise  model hatasını arttırabilir ama hızlıca eğitimin tamamlanmasınada sebep olabilir."
      ],
      "metadata": {
        "id": "XvbSLIghaJvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "RwVSejzoa5vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = {\n",
        "    'train': {\n",
        "         'loss': [], 'accuracy': []\n",
        "    },\n",
        "    'val': {\n",
        "         'loss': [], 'accuracy': []\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "rmF1OXhga-p4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "eğitim sırasında olanları loglamak için bir sözlük oluştuırduk."
      ],
      "metadata": {
        "id": "zIXH8LSXa_G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "## 30 epoch atacağımız için range30\n",
        "for epoch in range(30):\n",
        "  ## epoch datasını loglamak için\n",
        "  ep_metrics = {\n",
        "    'train': {'loss': 0, 'accuracy': 0, 'count': 0},\n",
        "    'val': {'loss': 0, 'accuracy': 0, 'count': 0},\n",
        "  }\n",
        "\n",
        "  print(f'Epoch {epoch}')\n",
        "\n",
        "  ##  her epochta train ve valiadation var\n",
        "  for phase in ['train', 'val']:\n",
        "    print(f'-------- {phase} --------')\n",
        "\n",
        "    # data loaderdan datayı al ve üzerinde gez\n",
        "    for images, labels in dataloaders[phase]:\n",
        "      #graidenti her tur sıfırlıyoruz yoksa graidentler birikir\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # görselleri modelden geçirdik\n",
        "      with torch.set_grad_enabled(phase == 'train'):\n",
        "        output = model(images.to(device))\n",
        "        # labelları one hot encode yapık (0 0 1  / 1 0 0 / 0 1 0)\n",
        "        ohe_label = torch.nn.functional.one_hot(labels, num_classes=3)\n",
        "\n",
        "        # sonuçla gerçeği kıyasla ve lossu bull\n",
        "        loss = criterion(output, ohe_label.float().to(device))\n",
        "        # argmax ile accuracy hesapla\n",
        "        correct_preds = labels.to(device) == torch.argmax(output, dim=1)\n",
        "        accuracy = (correct_preds).sum()/len(labels)\n",
        "\n",
        "      if phase == 'train':\n",
        "        # loss üzerinde backpropagete yap ve gradient hesapla\n",
        "        loss.backward()\n",
        "        # ağırlıkları güncelle\n",
        "        optimizer.step()\n",
        "\n",
        "      # metrikleri takip eder\n",
        "      ep_metrics[phase]['loss'] += loss.item()\n",
        "      ep_metrics[phase]['accuracy'] += accuracy.item()\n",
        "      ep_metrics[phase]['count'] += 1\n",
        "\n",
        "\n",
        "    ep_loss = ep_metrics[phase]['loss']/ep_metrics[phase]['count']\n",
        "    ep_accuracy = ep_metrics[phase]['accuracy']/ep_metrics[phase]['count']\n",
        "\n",
        "    print(f'Loss: {ep_loss}, Accuracy: {ep_accuracy}\\n')\n",
        "\n",
        "    metrics[phase]['loss'].append(ep_loss)\n",
        "    metrics[phase]['accuracy'].append(ep_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8NyMLWUbEQ8",
        "outputId": "2678983b-c7f4-4f2a-f0dd-6dd9afcc61cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "-------- train --------\n",
            "Loss: 0.726664662361145, Accuracy: 0.6861979179084301\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.6360697249571482, Accuracy: 0.6041666666666666\n",
            "\n",
            "Epoch 1\n",
            "-------- train --------\n",
            "Loss: 0.19137765932828188, Accuracy: 0.9518229179084301\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.5441703945398331, Accuracy: 0.6458333333333334\n",
            "\n",
            "Epoch 2\n",
            "-------- train --------\n",
            "Loss: 0.06165928166592494, Accuracy: 0.984375\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.5201831708351771, Accuracy: 0.8958333333333334\n",
            "\n",
            "Epoch 3\n",
            "-------- train --------\n",
            "Loss: 0.07003036618698388, Accuracy: 0.9830729179084301\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.6040978928407034, Accuracy: 0.5625\n",
            "\n",
            "Epoch 4\n",
            "-------- train --------\n",
            "Loss: 0.11002121662022546, Accuracy: 0.9557291679084301\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.6261329352855682, Accuracy: 0.5833333333333334\n",
            "\n",
            "Epoch 5\n",
            "-------- train --------\n",
            "Loss: 0.041242501145461574, Accuracy: 0.9921875\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.4883938630421956, Accuracy: 0.9166666666666666\n",
            "\n",
            "Epoch 6\n",
            "-------- train --------\n",
            "Loss: 0.07444414398923982, Accuracy: 0.9765625\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.5014259393016497, Accuracy: 0.625\n",
            "\n",
            "Epoch 7\n",
            "-------- train --------\n",
            "Loss: 0.05208676842448767, Accuracy: 0.98046875\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.36922551567355794, Accuracy: 0.9791666666666666\n",
            "\n",
            "Epoch 8\n",
            "-------- train --------\n",
            "Loss: 0.10761673602974042, Accuracy: 0.9401041679084301\n",
            "\n",
            "-------- val --------\n",
            "Loss: 1.1484975516796112, Accuracy: 0.5833333333333334\n",
            "\n",
            "Epoch 9\n",
            "-------- train --------\n",
            "Loss: 0.06757632808876224, Accuracy: 0.9765625\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.7521849249800047, Accuracy: 0.625\n",
            "\n",
            "Epoch 10\n",
            "-------- train --------\n",
            "Loss: 0.08215417843894102, Accuracy: 0.9713541679084301\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.9045884187022845, Accuracy: 0.6458333333333334\n",
            "\n",
            "Epoch 11\n",
            "-------- train --------\n",
            "Loss: 0.12448209384456277, Accuracy: 0.9518229179084301\n",
            "\n",
            "-------- val --------\n",
            "Loss: 1.1491703043381374, Accuracy: 0.5833333333333334\n",
            "\n",
            "Epoch 12\n",
            "-------- train --------\n",
            "Loss: 0.17882660910254344, Accuracy: 0.9466145820915699\n",
            "\n",
            "-------- val --------\n",
            "Loss: 1.0140059292316437, Accuracy: 0.6458333333333334\n",
            "\n",
            "Epoch 13\n",
            "-------- train --------\n",
            "Loss: 0.1761976529378444, Accuracy: 0.9440104179084301\n",
            "\n",
            "-------- val --------\n",
            "Loss: 1.0407241433858871, Accuracy: 0.6041666666666666\n",
            "\n",
            "Epoch 14\n",
            "-------- train --------\n",
            "Loss: 0.05320908178691752, Accuracy: 0.9791666679084301\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.6891205509503683, Accuracy: 0.6666666666666666\n",
            "\n",
            "Epoch 15\n",
            "-------- train --------\n",
            "Loss: 0.0394940340629546, Accuracy: 0.98046875\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.7597523971150318, Accuracy: 0.6458333333333334\n",
            "\n",
            "Epoch 16\n",
            "-------- train --------\n",
            "Loss: 0.025064408117032144, Accuracy: 0.9921875\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.7613724085191885, Accuracy: 0.625\n",
            "\n",
            "Epoch 17\n",
            "-------- train --------\n",
            "Loss: 0.04661395648145117, Accuracy: 0.98046875\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.6625845928986868, Accuracy: 0.625\n",
            "\n",
            "Epoch 18\n",
            "-------- train --------\n",
            "Loss: 0.07418255061929813, Accuracy: 0.984375\n",
            "\n",
            "-------- val --------\n",
            "Loss: 0.8099546407659849, Accuracy: 0.6666666666666666\n",
            "\n",
            "Epoch 19\n",
            "-------- train --------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the metrics\n",
        "\n",
        "\n",
        "Görselleştirme sıkıcı yazılardan çok daha iyidir."
      ],
      "metadata": {
        "id": "wllG_dPohq41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9kZgOPgthtKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for phase in metrics:\n",
        "    for metric in metrics[phase]:\n",
        "        metric_data = metrics[phase][metric]\n",
        "        plt.plot(range(len(metric_data)), metric_data)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel(f'{phase} {metric}')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "t1N03Itkh06U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}