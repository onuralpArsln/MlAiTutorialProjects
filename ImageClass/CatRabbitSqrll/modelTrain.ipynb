{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onuralpArsln/MlAiTutorialProjects/blob/main/ImageClass/CatRabbitSqrll/modelTrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-14cIIXG1NUt"
      },
      "source": [
        "# Pytorch ile Kendi Datasetinden Eğitim\n",
        "\n",
        "\n",
        "Bir çok tutorialda torchvision dataset içinden hızlıca bir dataset çekmek tercih edilir çünkü çok kolayca düzgün bir dataset oluşturmuş olursun.\n",
        "\n",
        "Biz bugün kendi elimizdeki bir data seti kullanarak bu işlemleri yapacağız.\n",
        "\n",
        "Bunun için bir bulk downloader uzantısı ile googledan bir çok resmi hızlıca kayıt edebilir ya da elimizdeki hazır bir seti kullanabiliriz. Araştırmalar sırasında video çekip bu videodan bir python scripti ile ekran görüntüleri almak gibi teknikler ile de veri setleri hızlıca oluşturulabilir\n",
        "\n",
        "ancak data bir miktar düzenlemeye ihtiyaç duyabilir.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0wc_m181NUu"
      },
      "source": [
        "# Database yapısı\n",
        "\n",
        "\n",
        "Oldukça basit bir yapıyı takip edeceğiz\n",
        "                                      \n",
        "data/                                           \n",
        "├─ cat/             \n",
        "│  ├─ image001.jpg             \n",
        "│  ├─ image002.jpg             \n",
        "│  ├─ ....             \n",
        "├─ rabbit/             \n",
        "│  ├─ image001.jpg             \n",
        "│  ├─ image002.jpg             \n",
        "│  ├─ ....      \n",
        "├─ squirrel/             \n",
        "│  ├─ image001.jpg             \n",
        "│  ├─ image002.jpg             \n",
        "│  ├─ ....         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3fQPwwG1NUv"
      },
      "source": [
        "Bu dosya hem zipli hem de sıkıştırılmamış olarak repoda mevcut. Zipli hali colabda çalışırken wget ile kolayca indirmen için"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9TrlErX1NUv"
      },
      "source": [
        "Colabde isen kolayca indir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e1RhwPL1NUv",
        "outputId": "08cc4319-db8f-4d55-d015-03cbf35bd324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-18 09:30:45--  https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/ImageClass/CatRabbitSqrll/data.zip\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/onuralpArsln/MlAiTutorialProjects/main/ImageClass/CatRabbitSqrll/data.zip [following]\n",
            "--2024-07-18 09:30:45--  https://raw.githubusercontent.com/onuralpArsln/MlAiTutorialProjects/main/ImageClass/CatRabbitSqrll/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76061926 (73M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  72.54M  85.2MB/s    in 0.9s    \n",
            "\n",
            "2024-07-18 09:30:50 (85.2 MB/s) - ‘data.zip’ saved [76061926/76061926]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/ImageClass/CatRabbitSqrll/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "geJT3k_G1NUv"
      },
      "outputs": [],
      "source": [
        "!unzip -q data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHJQJzAa1NUw"
      },
      "source": [
        "# Define Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i4zxds-1NUw"
      },
      "source": [
        "Transfromların olay resimlere rastgele değişimler uygulamaktır.  \n",
        "\n",
        "Bu hem elimizdeki data miktarını arttırmak için güzel bir metot hem de farklı koşullar altında da tanıma yapabilmek için önemli.\n",
        "\n",
        "Örneğin rastgele döndürmeler eklemek sayesinde eğer kedi baş aşağı durursa da onu tanıyacağız.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-AEkKLgN1NUw"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b85lyUt51NUw"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py5Fi-UL1NUw"
      },
      "source": [
        "# Data setimizi aktarmak\n",
        "\n",
        "Bu noktada bizim data setimiz düzenli olduğu için bir metot kullanacağız ancak düzensiz bir data setin var ise nasıl çalışman gerektiğinin örneğide olacak\n",
        "\n",
        "\n",
        "Ayrıca bizim data setimizde iki sınıf içinde yakın miktarda görsel var. Bu iyi bir dataset için önemli bir yapıdır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QipG5URR1sfO"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y4dXuXZz1uGb"
      },
      "outputs": [],
      "source": [
        "dataset = torchvision.datasets.ImageFolder(root='data', transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHU2pF_L2J7h"
      },
      "source": [
        "# Custom Dataset\n",
        "\n",
        "Eğer dataset dosya yapın bizim örnekteki gibi düzenli değil ise  aşağıdaki methodu uygulayacaksın. Ama düzenli bir datasetine sahip olmak her zaman daha iyidir.\n",
        "\n",
        "__init__(), __len__(), ve __get_item__() methodlarını tanımlamak zorundasın sistemin çalışması için"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOnGAbUL4Vl0"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "#glob ve os sistem dizin kontrolü için\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    # transform ve dosya adresi bilgilerini alarak objeyi başlatır.\n",
        "    def __init__(self, root_dir, transform):\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        # tercih edilen dosya uzantılarını buraya yaz bizde sadece png ve jpeg mevcut\n",
        "        for ext in ['png', 'jpg']:\n",
        "            self.image_paths += glob.glob(os.path.join(root_dir, '*', f'*.{ext}'))\n",
        "        # set oluşturmak her dizine sadece bir kere uğramak için\n",
        "        class_set = set()\n",
        "        # mevcut olan her resim adresini ekle\n",
        "        for path in self.image_paths:\n",
        "            class_set.add(os.path.dirname(path))\n",
        "        self.class_lbl = { cls: i for i, cls in enumerate(sorted(list(class_set)))}\n",
        "    #  veri  setinin boyutunu döndürebilmek için bir method\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    # idx indexideki veriyi yükler\n",
        "    def __getitem__(self, idx):\n",
        "        img = read_image(self.image_paths[idx], ImageReadMode.RGB).float()\n",
        "        cls = os.path.basename(os.path.dirname(self.image_paths[idx]))\n",
        "        label = self.class_lbl[cls]\n",
        "        # label bilgisinide paylaşır\n",
        "        return self.transform(img), torch.tensor(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3z695gR4YvT"
      },
      "outputs": [],
      "source": [
        "custom_dataset = CustomDataset('data/', transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqXzZTEH2kIV"
      },
      "source": [
        "# Split Data\n",
        "\n",
        "\n",
        "Amacımız test, validation  ve train oluşturmak.\n",
        "\n",
        "train-> eğitim için kullanılcak veri\n",
        "\n",
        "validation -> eğitim sırasında parametre optimizasyonu için kullanılan veri kısmı\n",
        "\n",
        "test-> model eğitildikten sonra performans ölçümü için kullanılır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rJe9yIGn2oWW"
      },
      "outputs": [],
      "source": [
        "splits = [0.8, 0.1, 0.1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aE4f8NqT3iDS"
      },
      "outputs": [],
      "source": [
        "split_sizes = []\n",
        "for sp in splits[:-1]:\n",
        "    split_sizes.append(int(sp * len(dataset)))\n",
        "split_sizes.append(len(dataset) - sum(split_sizes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MKcpD1mO2_B9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.utils\n",
        "train_set, test_set, val_set = torch.utils.data.random_split(dataset, split_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0eW1ruu_3o3O"
      },
      "outputs": [],
      "source": [
        "train_set, test_set, val_set = torch.utils.data.random_split(dataset, split_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U7ANJfsp3qA6"
      },
      "outputs": [],
      "source": [
        "val_set.transform = test_set.transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcbuVlLO3rq-"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp_HfAbW6Euy"
      },
      "source": [
        "Dataloader pytorch içinde iterasyona izin veren bir yapıdır. böylece verilerini pytorch içinde kullanılacak bir yapıya çevirirsin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AeRNBRWu3uBc"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oJQNiAMg3vBJ"
      },
      "outputs": [],
      "source": [
        "dataloaders = {\n",
        "    \"train\": DataLoader(train_set, batch_size=16, shuffle=True),\n",
        "    \"test\": DataLoader(test_set, batch_size=16, shuffle=False),\n",
        "    \"val\": DataLoader(val_set, batch_size=16, shuffle=False)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va_eWoTW4As2"
      },
      "source": [
        "# Define the Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnhWPHRY6UgY"
      },
      "source": [
        "Sınıflandırmayı yapan modele classifier denir.\n",
        "\n",
        "her nöral yapı gibi classifier de katmanlardan oluşur. bu katmanları istersek kendimiz elle belirleyebiliriz. Ancak uzmanların hazırladığı güçlü yapılarda pytorch içinden kolayca ulaşılabilir.  Bu tutorialde amacımız öğrenmek olduğu için nasıl yapılıyor göreceğiz ama bir mühendislik uygulaması sırasında iyi ve hazır bir nöral yapıyı kullanmak iyi fikirdir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aduuQKbE7AXS"
      },
      "source": [
        "## Custom Architecture\n",
        "\n",
        "aşağıda iki farklı yapı var. eğer ikiden çok çıkışın / sınıfın varsa çok sayıda nöron gerekir\n",
        "\n",
        "1 0 0      kedi       \n",
        "0 1 0      tavşan                        \n",
        "0 0 1      sincap                    \n",
        "gibi            \n",
        "\n",
        "ancak eğer iki  çıkış lazımsa            \n",
        "1 kuş             \n",
        "0 tavşan                   \n",
        "\n",
        "yapabilirsin.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFmXiRgA4FVs"
      },
      "outputs": [],
      "source": [
        "## Çok sınıflı sınıflandırma için\n",
        "\n",
        "\n",
        "class CustomModel(torch.nn.Module):   ## custom model yapmak için miras alınıyor\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__() ## miras alınan parentin init çalışıyor\n",
        "\n",
        "        # linear ( fully connected) bir giriş 128 boyutlu girdi alıyor ve\n",
        "        #256 boyutunda bir tensor dışarı veriyor\n",
        "        self.linear1 = torch.nn.Linear(128, 256)\n",
        "\n",
        "        # ReLu Rectified Linear Unit aktivasyonu ilk layerdan sonra kullanılıyor\n",
        "        self.activation = torch.nn.ReLU()\n",
        "\n",
        "        # aşağıdaki 3 sayısı 3 sınıf olduğu için 4 olsa 4 yazardık\n",
        "        # iki katman var giriş ve çıkış 128 girdi 3 çıktı\n",
        "        self.linear2 = torch.nn.Linear(256, 3)\n",
        "\n",
        "        # soft max katmanı çıktıyı olasılığa dönüştürür.\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "\n",
        "  # ileri yönde modelde harekti yapıyoruz\n",
        "  # x datasını katmanlardan geçiriyor ve sonucu döndürüyor\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0COLmObi4IZ5"
      },
      "outputs": [],
      "source": [
        "## Binary ikili sınıflandırma içi\n",
        "class CustomModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(128, 256)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(256, 1)\n",
        "        self.softmax = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}