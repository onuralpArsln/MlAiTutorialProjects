{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch ile Kendi Datasetinden Eğitim\n",
    "\n",
    "\n",
    "Bir çok tutorialda torchvision dataset içinden hızlıca bir dataset çekmek tercih edilir çünkü çok kolayca düzgün bir dataset oluşturmuş olursun.\n",
    "\n",
    "Biz bugün kendi elimizdeki bir data seti kullanarak bu işlemleri yapacağız.\n",
    "\n",
    "Bunun için bir bulk downloader uzantısı ile googledan bir çok resmi hızlıca kayıt edebilir ya da elimizdeki hazır bir seti kullanabiliriz. Araştırmalar sırasında video çekip bu videodan bir python scripti ile ekran görüntüleri almak gibi teknikler ile de veri setleri hızlıca oluşturulabilir\n",
    "\n",
    "ancak data bir miktar düzenlemeye ihtiyaç duyabilir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database yapısı\n",
    "\n",
    "\n",
    "Oldukça basit bir yapıyı takip edeceğiz \n",
    "                                      \n",
    "data/                                           \n",
    "├─ cat/             \n",
    "│  ├─ image001.jpg             \n",
    "│  ├─ image002.jpg             \n",
    "│  ├─ ....             \n",
    "├─ rabbit/             \n",
    "│  ├─ image001.jpg             \n",
    "│  ├─ image002.jpg             \n",
    "│  ├─ ....             \n",
    "├─ squirrel/             \n",
    "│  ├─ image001.jpg             \n",
    "│  ├─ image002.jpg             \n",
    "│  ├─ ....             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu dosya hem zipli hem de sıkıştırılmamış olarak repoda mevcut. Zipli hali colabda çalışırken wget ile kolayca indirmen için"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colabde isen kolayca indir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/onuralpArsln/MlAiTutorialProjects/raw/main/ImageClass/CatRabbit/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfromların olay resimlere rastgele değişimler uygulamaktır.  \n",
    "\n",
    "Bu hem elimizdeki data miktarını arttırmak için güzel bir metot hem de farklı koşullar altında da tanıma yapabilmek için önemli.\n",
    "\n",
    "Örneğin rastgele döndürmeler eklemek sayesinde eğer kedi baş aşağı durursa da onu tanıyacağız.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setimizi aktarmak\n",
    "\n",
    "eğer data setimiz kurallara uygun bir yapıda ise işimiz kolay. Dosya yapısı aşağıdaki gibi ise süreç çok kolay.\n",
    "              \n",
    "data/                                           \n",
    "├─ cat/             \n",
    "│  ├─ image001.jpg             \n",
    "│  ├─ image002.jpg             \n",
    "│  ├─ ....             \n",
    "├─ rabbit/             \n",
    "│  ├─ image001.jpg             \n",
    "│  ├─ image002.jpg             \n",
    "│  ├─ ....             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='data', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "root data adressi  \n",
    "transform ise önceden belirtilen transformlardır. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image, ImageReadMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform):\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        # kullandığın tüm uzantıları formatları buraya ekle \n",
    "        for ext in ['png', 'jpg']:\n",
    "            self.image_paths += glob.glob(os.path.join(root_dir, '*', f'*.{ext}'))\n",
    "        class_set = set()\n",
    "        for path in self.image_paths:\n",
    "            class_set.add(os.path.dirname(path))\n",
    "        self.class_lbl = { cls: i for i, cls in enumerate(sorted(list(class_set)))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = read_image(self.image_paths[idx], ImageReadMode.RGB).float()\n",
    "        cls = os.path.basename(os.path.dirname(self.image_paths[idx]))\n",
    "        label = self.class_lbl[cls]\n",
    "\n",
    "        return self.transform(img), torch.tensor(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
